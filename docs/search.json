[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "En 2017, AgroParisTech signe l’Appel de Jussieu pour promouvoir la bibliodiversité, visant à maintenir la diversité éditoriale et éviter la domination des grands groupes éditeurs. AgroParisTech, en partenariat avec INRAE, adopte en 2020 une politique de science ouverte (AgroParisTech (2024), voir: La science ouverte à AgroParisTech – Politique d’établissement janvier 2020), facilitant la libre diffusion et la transparence des recherches scientifiques. Un exemple concret des principes appliqués suite à l’adoption de cette politique sont les principes FAIR pour la gestion des données de recherche : Findable (facilement trouvable), Accessible (accès clairement défini), Interoperable (intégrable avec d’autres outils), et Reusable (réutilisable avec toutes les informations nécessaires).\nPour atteindre ces objectifs, AgroParisTech crée le 2 janvier 2023 une cellule HAL, dirigée par la Direction de la Recherche, de l’Innovation et du Transfert Technologique, et par la Direction de la Documentation et du Patrimoine Culturel. Cette cellule facilite l’intégration de l’archive ouverte HAL dans la communauté de recherche d’AgroParisTech et veille à la qualité des métadonnées. HAL, ou HyperArticles en Lignes, est “l’archive nationale pour la diffusion ouverte des résultats de recherche” (“About HAL” (n.d.)). Elle est une plateforme en ligne développé en 2001 par le Centre pour la communication scientifique directe du CNRS. Cette plateforme dispose d’un API permettant l’extraction et l’analyse des données via des outils comme RStudio. Une explication plus détaillée de cet API et d’une requête HAL sera faite dans la section méthode.\n\n\n\nLes outils pour réaliser des analyses bibliométriques se répartissent en trois catégories, “general bibliometric and performance analysis, science mapping analysis, and libraries” (Moral-Muñoz et al. (2020)) ou analyse générale bibliométrique et de performances, analyses par cartographie scientifique et librairies / packages. Le package {managHAL} se trouve dans les troisième et deuxième catégories. Il existe à ce jour d’autres outils d’analyses bibliométriques mais la majorité ne permettent pas de travailler via l’api HAL et se concentrent sur webofscience, scopus, google scholar,… Il existe des outils d’extraction de publications HAL, cependant aucun package R ne permet actuellement d’extraire ces données pour réaliser des analyses statisistiques. Pour répondre à ce besoin, Théodore Vanrengterghem a commencé à développer le package R {managHAL}. Le package permet l’extraction de données HAL et la création de bilans bibliographiques. En cours de développement, ce package ne permet pas actuellement la réalisation d’analyses bibliométriques.\nAinsi, durant mes 2 mois et 17 jours de stage au sein de l’unité mixte de recherche Mathématiques et Informatique Appliquées (MIA) - Paris Saclay, associée aux tutelles AgroParisTech, INRAE et Université Paris Saclay, j’ai travaillé sur rendre le package {managHAL} plus accessible et utilisable par d’autres unités de recherches que l’unité MIA - Paris Saclay. J’ai aussi travaillé sur la programmation et l’intégration d’outils d’analyse statistique de réseau au sein du package. Encadré par deux tuteurs, Julie Aubert et Pierre Barbillon, j’ai contribué à la mise en forme du package et à la création de fonctions spécifiques.\nPour comprendre les choix réalisés lors du développement du package, il est nécessaire de réaliser une introduction aux réseaux. Un réseau d’interaction est constitué de nœuds (les entités) et d’arêtes (les liens entre ces entités). Dans le cadre du package {managHAl}, j’utiliserai les réseaux pour modéliser un réseau de co-publications (ou co-auteurs). Les noeuds représenteront des auteurs, et les arêtes entre ces noeuds (auteurs) seront l’existence de publications scientifiques co-écrite par les deux noeuds. La taille d’un nœud représentera le nombre de publications écrites par cet auteur (noeud) et la largeur d’une arête pourra correspondre au nombre de publications co-ecrites par les deux noeuds (co-auteurs). Les réseaux ne sont cependant pas exclusifs à l’analyse de données bibliométriques. En effet, les réseaux sont utilisés comme représentation et comme objet d’analyse statistique dans de nombreux domaines. Par exemple, des réseaux de régulations de gènes sont réalisés à partir de données de co-expression. Il est possible de donner d’autres exemples comme les analyses de réseaux d’interactions entre des espèces (réseau trophique) réalisées en écologie (analyse réalisée dans une vignette du package {sbm}). Les utilisations des réseaux sont nombreuses. L’introduction aux réseaux et leurs analyses sera approfondie dans la section méthodes.\nCe package s’adresse donc à un public souhaitant réaliser des analyses bibliométriques approfondies à partir de HAL. Nous verrons cependant dans la section discussion qu’il est possible d’élargir les usages du package.\n\n\n\n\n\n\nCette partie est principalement basée sur la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022).\nLes réseaux se divisent en deux catégories principales (voir figures suivantes): les réseaux unipartites où tous les nœuds sont du même type et les réseaux bipartites où il y a deux types distincts de nœuds, et les liens ne se forment qu’entre des nœuds de types différents.(voir exemple_reseau_unipartite_bipartite pour le code de réalisation des réseaux d’exemple)\nExemple des deux types de réseaux\n \nLes interactions dans un réseau peuvent être binaires ou pondérées. Un réseau peut être représenté par une matrice d’adjacence \\(Y\\) où :\n\\[\\begin{align*}\nY_{ij} \\neq 0 & \\quad \\text{si un lien existe entre les nœuds } i \\text{ et } j, \\\\\nY_{ij} = 0 & \\quad \\text{si aucun lien n'existe entre les nœuds } i \\text{ et } j.\n\\end{align*}\\]\nNous décrivons les noeuds d’un réseau comme : \\(V = { 1,..,N }\\) , (\\(N\\) correspond à la taille du réseau). Les arêtes peuvent être décrites comme \\(E = \\{ (i,j) | i,j \\in V \\}\\) représentant les paires de nœuds entre lesquels il existe une interaction. Chaque arête \\((i,j)\\) indique une connexion entre les nœuds \\(i\\) et \\(j\\).\nIl existe plusieurs approches différentes pour analyser la structure d’un réseau. Dans ce mémoire, une seule approche sera considérée. Elle suppose l’existence de groupes fonctionnels partageant un même patron de connexion. Nous nous baserons par la suite sur une méthode possible pour cette approche: les modèles probabilistes génératifs.\nLes Modèles en Bloc Stochastiques (aussi appelés SBM) sont des modèles probabilistes. Ils supposent que les nœuds d’un même réseau sont divisés en blocs (groupes, clusters) latents regroupant les entités ayant des modèles de connectivité similaires. Latents signifie qu’il n’y a pas d’a priori sur le type de structure recherchée. Ces modèles sont utiles pour détecter les communautés, les clusters au sein d’un réseau complexe. Pour réaliser un modèle en bloc stochastique, il est nécessaire de supposer que le réseau obtenu à partir de mes données est une réalisation de mon modèle.\nLes noeuds sont partitionnés en \\(K\\) groupes latents. On définit un vecteur \\(Z\\) où \\(Zi = k\\) , \\(k\\) est le bloc auquel appartient le noeud \\(i\\) . Dans le cas d’un réseau unipartite, on définit :\n\n\\(P(Zi = k) = \\pi_k\\) , comme la probabilité d’appartenance au groupe \\(k\\).\n\\(P(Y_{ij} = 1 | Z_i = k, Z_j = k') = \\gamma_{kk'}\\) , comme la probabilité pour une paire de noeuds appartenant à un bloc \\(k\\) et à un bloc \\(k'\\) d’être en interaction (dans le cas binaire).\n\nNous avons donc comme paramètres du modèle \\(\\theta = (\\gamma, \\pi)\\). A partir du réseau connu, il est possible d’inférer les paramètres du modèle. Par nécessité d’écourter le rapport, une explication détaillée ne sera pas réalisée. Je vous conseille cependant d’aller voir la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022) où les explications à ce propos sont claires et précises.\n\n\n\nComme précisé dans l’introduction, l’intégralité des méthodes informatiques développées ont été réalisées sur RStudio en utilisant le langage R version 4.4.1 sous Windows 11 x64. Les packages utilisés sont les suivants :\nLe package {dplyr} (Wickham et al. 2023) est utilisé pour la manipulation et la transformation des données grâce à une syntaxe claire et cohérente. Ce package facilite les opérations courantes telles que la sélection, le filtrage, le regroupement et le résumé des données. Le package {mailR} (Premraj 2021) est utilisé pour l’envoi d’emails avec des pièces jointes directement depuis R, ce qui est utile pour automatiser l’envoi de rapports. Le package {askpass} (Ooms 2023) est utilisé pour gérer les mots de passe de manière sécurisée. Le package {furrr} (Vaughan and Dancho 2022) est utilisé pour paralléliser les tâches en combinaison avec le package future (Bengtsson 2021). Le package {future} (Bengtsson 2021) permet l’exécution de code en parallèle, ce qui réduit le temps de traitement des tâches lourdes. Le package {ggplot2} (Wickham 2016) est utilisé pour la création de visualisations graphiques sophistiquées. Le package {magrittr} (Bache and Wickham 2022) fournit des opérateurs pour améliorer la lisibilité du code, en particulier l’opérateur %&gt;% (pipe). Le package {purrr} (Wickham and Henry 2023) est utilisé pour les opérations fonctionnelles sur les listes et autres structures de données. Le package {quarto} (Allaire and Dervieux 2024) est utilisé pour la création de documents dynamiques et de rapports. Le package {readxl} (Wickham and Bryan 2023) permet la lecture de fichiers Excel. Le package {rvest} (Wickham 2024) est utilisé pour le web scraping, c’est-à-dire l’extraction de données à partir de pages web. Le package {SnowballC} (Bouchet-Valat 2023) est utilisé pour le traitement de la langue naturelle, en particulier pour la lemmatisation. Le package {stringr} (Wickham 2023) fournit des fonctions pour la manipulation des chaînes de caractères. Le package {tictoc} (Izrailev 2024) est utilisé pour mesurer le temps d’exécution des morceaux de code. Le package {tm} (Feinerer and Hornik 2024) est utilisé pour le text mining (extraction de connaissances à partir de textes). Le package {wordcloud} (Fellows 2018) est utilisé pour la création de nuages de mots. Le package {Visnetwork} (Chiquet, Donnet, and Barbillon 2020) est utilisé pour la visualisation de réseaux dynamiques. Le package {Sbm} (Chiquet, Donnet, and Barbillon 2024) est utilisé pour réaliser les analyses statistiques de réseaux.\nAfin de pouvoir construire une requête HAL pour récupérer des données bibliographiques de publications d’auteurs, il est nécessaire de comprendre comment construire une requête. Pour construire une requête HAL, il faut au moins un paramètre q qui contient la requête de recherche. Ce paramètre doit spécifier le champ de recherche suivi de la valeur. Par exemple, pour rechercher le terme “test” : http://api.archives-ouvertes.fr/search/?q=test&wt=xml . Si le champ n’est pas spécifié, la recherche s’effectue par défaut dans l’index texte. Pour rechercher dans un champ particulier, il faut utiliser champ:terme : http://api.archives-ouvertes.fr/search/?q=title_t:japon&wt=xml . Pour échapper certains caractères spéciaux utilisés par Apache Solr, utilisez \\. Par exemple, (1+1):2 devient \\(1\\+1\\)\\:2. (voir “Documentation API-HAL” (n.d.)). Il est possible d’indiquer le format de la réponse (sous-entendant le format des données récupérées) via le paramètre wt . Pour finir il est possible de spécifier les champs à retourner dans la réponse via le paramètre fl et de faire un filtre des données via le paramètre fq (“Documentation API-HAL” (n.d.)). Toutes les possibilités de l’API HAL n’ont pas été abordées dans ce court résumé. Il est pourtant compréhensible que l’API HAL est très diverse et permet une grande liberté à l’utilisateur pour l’extraction des données. De plus, il existe un nombre de champs considérables. Certains seront abordés par la suite dans la section résultats.\nPour finir, la totalité du stage s’est inscrit dans une dynamique de développement et d’intégration continue via la forge Gitlab d’INRAE. La forge GitLab, est un logiciel DevOps passant par le langage Git. Git est un système de contrôle, de versionning du code des développeurs gratuit et open source. Il permet à plusieurs développeurs de travailler sur un code sur un même dépôt et d’avancer ensemble par le biais de “merge”. “Merge” signifie que la personne modifiant un fichier contenant du code pousse en ligne sur le dépôt partagé , les modifications réalisées.\n\n\n\n\nCette section présente les résultats obtenus au cours de mon stage. Elle est divisée en deux parties principales: Les modifications faites au package {managHAL} d’origine dans l’objectif de le rendre plus générique et plus accessible, puis l’ajout de fonctionnalités au package {managHAL}. Par choix, seulement certaines fonctions et scripts R du package sont abordés. L’exécution de ces derniers est réalisée par le biais d’un exemple. Cet exemple est basé sur des données de l’UMR MIA-Paris-Saclay. Chaque fonction est expliquée en détail, suivie des raisons justifiant son développement. Il est important de noter que mon stage se terminant le 26 juillet, Le package est encore en développement. Certaines fonctionnalités sont encore en travail. Les fonctions présentées fonctionnent dans le cadre de l’exemple. Si vous souhaitez exécuter les scripts fournis dans le mémoire, il est nécessaire d’avoir accès au package {managHAL}. Dans cette section, les noms de fonctions seront en italique et les noms des scripts R contenant les fonctions seront en gras.\n\n\nLors de mon stage, j’ai d’abord décidé de rendre le package plus accessible et générique. Pour ce faire, il m’était nécessaire de réorganiser et modifier certaines fonctions déjà présentes codées par Théodore Vanrengterghem.\n\n\nJ’ai commencé par modifier dans le fichier mia_table.R la fonction load_mia_table. A l’origine, cette fonction permettait le chargement d’un csv en ligne fourni par les Ressources Humaines depuis un serveur. Le fichier contient des informations telles que le nom, le prénom, l’idhal, l’équipe, etc, des personnes appartenant au labo. Cette fonction n’était pas générique. Ainsi, il était nécessaire de la modifier. J’ai fait le choix de renommer le fichier load_table.R. J’ai remplacé la fonction load_mia_table par trois fonctions load_team_table_csv, load_team_table_url, et load_team_table. J’ai aussi modifié la majorité des fonctions déjà présentes dans le package faisant appel à load_mia_table. Les paramètres en entrée des trois fonctions sont les même que la fonction load_mia_table d’origine avec l’ajout d’un paramètre permettant à l’utilisateur de rentrer l’adresse du fichier. J’ai ensuite créé une documentation via le package {roxygène2} conforme aux critères requis pour un package mis en ligne (veuillez vous référez à l’annexe : Exemple d’une documentation classique avec Roxygen2 ) pour chacune des trois fonctions.\nload_team_table_url permet de charger un csv dans RStudio depuis un fichier en ligne. J’ai décidé pour load_team_table_url de garder en majeur partie le code d’origine et de simplement le réadapter par soucis de temps. J’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table_url)\nload_team_table_csv est basée sur la construction de load_team_table_url. Je l’ai adapté pour pouvoir charger depuis un fichier local de la machine de l’utilisateur en utilisant read.csv. De même que dans load_team_table_url, j’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table_csv)\nEnfin, load_team_table appelle l’une des deux fonctions en fonction du type d’adresse fourni : URL ou chemin de fichier local. Le type de l’adresse est déterminé en utilisant grepl, qui utilise une expression régulière. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table)\n\n\n\n\ndata_RH_csv_Example &lt;- load_team_table(filter_id = TRUE,\n    date_cols = c(6, 7), filepath_or_url = \"./data/Data_RH_Example.csv\")\n# afin de ne garder que les lignes avec un idhal\n# correct\ndata_RH_csv_Example &lt;- data_RH_csv_Example[which(!is.na(data_RH_csv_Example$idhal)),\n    ]\nhead(data_RH_csv_Example)\n\n  civilite       nom prenom statut  rattachement debut_contrat fin_contrat\n1       M. ADJAKOSSA   Éric    CEC AgroParisTech                          \n6      Mme    AUBERT  Julie     IR         INRAE                          \n8       M. BARBILLON Pierre     PR AgroParisTech                          \n  financement  equipe  unite               orcid  idhal\n1             SOLsTIS MIA PS 0000-0002-5280-0347 749339\n6             SOLsTIS MIA PS 0000-0001-5203-5748  15356\n8             SOLsTIS MIA PS 0000-0002-7766-7693  16750\n                       adresse_mail\n1   eric-houngla.adjakossa@inrae.fr\n6             julie.aubert@inrae.fr\n8 Pierre.Barbillon@Agroparistech.fr\n\n\nLors de l’application de la fonction load_team_table ci-dessus en utilisant le jeu de données test Data_RH_Example, on observe le chargement d’un csv contenant les colonnes d’origine du csv fournies en entrée. Les valeurs manquantes ou mal renseignées des idhals numériques ont été remplacées par des NAs. Les dates présentes dans les colonnes de dates spécifiées par l’utilisateur ont été nettoyées et ont le bon format.\n\n\n\nDans le package {managHAL} originel, il y avait deux fichiers contenant les fonctions nécessaires à la construction d’une requête HAL. Ces deux fichiers se nomment HAL_reports.R et HAL_queries.R. La fonction principale de construction d’une requête HAL est HAL_query. Elle prend en entrée différents paramètres et construit une url correspondant à une requête HAL. Ces différents paramètres définissent les différents champs, filtres, sorties demandées de la requête. Les champs de sortie ne convenant pas et manquait d’information pour la construction d’un réseau. Ainsi, après réflexion et discussion avec mes tuteurs Julie Aubert et Pierre Barbillon, j’ai modifié les différents champs de sorties afin d’obtenir les données nécessaires et essentielles à la construction d’un réseau. Par exemple, le champ ‘authFullNamePersonIDIDHal_fs’ permet de spécifier à HAL_query de récupérer les noms et les identifiants HAL numériques des autheurs d’une même publication. Le paramètre add_output ajouté par Théodore Vanrengterghem dans la fonction d’origine permet à l’utilisateur de rentrer des champs de sortie spécifiques en plus. Ce paramètre a été beaucoup utilisé au cours de ce stage dans la création de fonction permettant la création de réseau.\nLa fonction d’origine ne créer pas d’url d’une page permettant de récupérer les publications autres qu’à partir d’identifiants numériques d’auteurs, j’ai modifié les paramètres d’entrée et le corps de la fonction afin que l’utilisateur puissent spécifier si les identifiants fournis sont des identifiants de structures ou des identifiants de personnes. La nouvelle fonction HAL_query crée un url qui peut récupérer au choix de l’utilisateur une liste de publications associés à une structure via son identifiant ou une liste de publications associés à un identifiant numérique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : HAL_query)\nPlusieurs fonctions présentes avant mes modifications faisait appel à HAL_query. Ces dernières comme HAL_extract_csv ont donc été modifiées afin de correspondre à la nouvelle version de HAL_query. De même Les fonctions auquelles fait appel HAL_query ont elles aussi été modifiées pour correspondre à HAL_query. HAL_extract_csv est une fonction récupèrant l’url via HAL_query. Pour montrer les résultats obtenus avec HAL_query, des exemples ci-dessous seront réalisés avec HAL_extract_csv pour une liste d’identifiants numérique d’auteurs et pour un identifiant d’une unité/laboratoire. Il sera ajouté des sorties via le paramètres add_outputs :\n\ndate_min = \"01/01/2022\"\ndate_max = \"01/01/2023\"\n\n# Publications à partir d'un id de laboratoire.\nHAL_publis_Labo &lt;- managHAL::HAL_extract_csv(id = 1002311,\n    date_min, date_max, type_id = \"struct_id\", add_output = c(\"structAcronym_s\",\n        \"structId_i\", \"structHasAlphaAuthIdHalPersonid_fs\"))\nHAL_publis_Labo[1, ]\n\n    docid      halId_s version_i docType_s\n1 4440523 hal-04440523         1      COMM\n                                                                                                                                                                                                                                                                                                                                                                         citationFull_s\n1 Isabelle Lebert, Maxime Rates, Julien Pradel, Laure Mathews-Martin, Aurore Latour, et al.. Evaluation du risque d’exposition aux tiques et aux agents de la maladie de Lyme dans les espaces verts de la région lyonnaise : résultats de la surveillance 2019-2023. Colloque final de restitution du projet Biodiversa-Bioroddi, Nov 2023, Lyon (Sciences Po), France. ⟨hal-04440523⟩\n                                                                                      citationRef_s\n1 Colloque final de restitution du projet Biodiversa-Bioroddi, Nov 2023, Lyon (Sciences Po), France\n  publicationDate_tdate\n1  2023-01-01T00:00:00Z\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    authFullNamePersonIDIDHal_fs\n1 Isabelle Lebert_FacetSep_184610_FacetSep_isabelle-lebert,Maxime Rates_FacetSep_749136_FacetSep_maxime-rates,Julien Pradel_FacetSep_1284695_FacetSep_,Laure Mathews-Martin_FacetSep_1310514_FacetSep_,Aurore Latour_FacetSep_0_FacetSep_,Maximilien Barbier_FacetSep_0_FacetSep_,Gwenaël Vourc’h_FacetSep_736823_FacetSep_gwenael-vourch,Valerie Poux_FacetSep_744163_FacetSep_valerie-poux,Séverine Barry_FacetSep_744034_FacetSep_severine-barry,Sébastien Masseglia_FacetSep_744051_FacetSep_sebastien-masseglia,Severine Bord_FacetSep_180861_FacetSep_severine-bord,Karine Chalvet-Monfray_FacetSep_743281_FacetSep_karine-chalvet-monfray,Diana Sepúlveda_FacetSep_0_FacetSep_,Luc Chabanne_FacetSep_754272_FacetSep_luc-chabanne,Nathalie Charbonnel_FacetSep_736426_FacetSep_nathalie-charbonnel,Magalie René-Martellet_FacetSep_744046_FacetSep_magalie-rene-martellet\n                                                                                               structAcronym_s\n1 UMR EPIA,VAS,INRAE,UMR CBGP,Cirad,IRD [France-Sud],INRAE,Institut Agro,UM,LRFSN,ANSES,MIA Paris-Saclay,INRAE\n                                                                                                                            structId_i\n1 1002382,301767,577435,1100832,11574,451860,577435,1096330,1042499,1100589,561191,301715,1002311,148117,419361,577435,1056557,1031275\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             structHasAlphaAuthIdHalPersonid_fs\n1 L_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,L_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,L_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,R_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,R_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,R_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,P_AlphaSep_1100832_FacetSep_Centre de Biologie pour la Gestion des Populations_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_11574_FacetSep_Centre de Coopération Internationale en Recherche Agronomique pour le Développement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_451860_FacetSep_Institut de Recherche pour le Développement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1096330_FacetSep_Institut Agro Montpellier_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1042499_FacetSep_Institut national d'enseignement supérieur pour l'agriculture\\\\, l'alimentation et l'environnement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1100589_FacetSep_Université de Montpellier_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,M_AlphaSep_561191_FacetSep_Laboratoire de la rage et de la faune sauvage de Nancy_JoinSep__FacetSep_1310514_FacetSep_Mathews-Martin Laure,M_AlphaSep_301715_FacetSep_Agence nationale de sécurité sanitaire de l'alimentation\\\\, de l'environnement et du travail_JoinSep__FacetSep_1310514_FacetSep_Mathews-Martin Laure,L_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep__FacetSep_0_FacetSep_Latour Aurore,L_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep__FacetSep_0_FacetSep_Latour Aurore,L_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_0_FacetSep_Latour Aurore,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,V_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,V_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,V_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,P_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,P_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,P_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,M_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,M_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,M_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_1002311_FacetSep_Mathématiques et Informatique Appliquées_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_148117_FacetSep_AgroParisTech_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_419361_FacetSep_Université Paris-Saclay_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,C_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,C_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,S_AlphaSep_1056557_FacetSep_Direction ‑ Écologie Urbaine de la Ville de Lyon_JoinSep__FacetSep_0_FacetSep_Sepúlveda Diana,S_AlphaSep_1031275_FacetSep_Partenaires INRAE_JoinSep__FacetSep_0_FacetSep_Sepúlveda Diana,C_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_1100832_FacetSep_Centre de Biologie pour la Gestion des Populations_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_11574_FacetSep_Centre de Coopération Internationale en Recherche Agronomique pour le Développement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_451860_FacetSep_Institut de Recherche pour le Développement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1096330_FacetSep_Institut Agro Montpellier_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1042499_FacetSep_Institut national d'enseignement supérieur pour l'agriculture\\\\, l'alimentation et l'environnement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1100589_FacetSep_Université de Montpellier_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,R_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie,R_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie,R_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie\n\n# Publications à partir d'ids auteurs\nHAL_publis_auteurs &lt;- managHAL::HAL_extract_csv(id = data_RH_csv_Example[,\n    12], date_min, date_max, type_id = \"person_id\")\nHAL_publis_auteurs[1, ]\n\n    docid      halId_s version_i docType_s\n1 4190551 hal-04190551         1       ART\n                                                                                                                                                                                                                                                                                citationFull_s\n1 Emmanuelle Blanc, Jérôme Enjalbert, Timothée Flutre, Pierre Barbillon. Efficient Bayesian automatic calibration of a functional-structural wheat model using an adaptive design and a metamodeling approach. Journal of Experimental Botany, In press, ⟨10.1093/jxb/erad339⟩. ⟨hal-04190551⟩\n                                                    citationRef_s\n1 Journal of Experimental Botany, In press, ⟨10.1093/jxb/erad339⟩\n  publicationDate_tdate\n1  2023-01-01T00:00:00Z\n                                                                                                                                                                                         authFullNamePersonIDIDHal_fs\n1 Emmanuelle Blanc_FacetSep_0_FacetSep_,Jérôme Enjalbert_FacetSep_1169771_FacetSep_jerome-enjalbert,Timothée Flutre_FacetSep_11756_FacetSep_timothee-flutre,Pierre Barbillon_FacetSep_16750_FacetSep_pierre-barbillon\n\n\n\n\n\n\n\n\nAfin d’obtenir les informations sous-jacentes des données bibliographiques, j’ai commencé à travailler à la création d’un réseau de co-auteur. Pour l’instant, la fonctionnalité n’existe qu’au format de script R sur un document quarto. Au cours des semaines restantes, l’objectif est de continuer à travailler dessus et créer des fonctions simples et claires permettant à l’utilisateur de créer son propre réseau à partir de ses données. Le script de création de fonction est inspiré d’un script fournie au préalable par ma tutrice Julie Aubert. Des modifications et des ajouts ont été apportés pour améliorer l’extraction, le nettoyage, la construction, et la visualisation des données. Suite à mes modifications et mes ajouts, le script se divise en plusieurs parties ((Pour voir le script R, veuillez vous référer à l’annexe : Script_R_reseau_co-auteur) :\nLa première partie correspond à l’extraction et au nettoyage des données. Les données brutes ont été organisées et nettoyées pour être adaptées à la construction du réseau. Les années de publication ont été extraites et les identifiants des auteurs ont été nettoyé. Les auteurs ont été associés aux structures pertinentes, et les incohérences de noms ou d’identifiants HAL ont été corrigées. Des identifiants fictifs ont été créés pour les auteurs sans identifiant.\nLa deuxième partie concerne la construction et la visualisation du graphe. À partir des données nettoyées, des matrices de contingence ont été créées. Ces matrices ont été converties en listes de nœuds (auteurs) et en listes d’arêtes (collaborations). Les nœuds ont été colorés et groupés en fonction des années de publication, et des légendes ont été ajoutées pour faciliter la compréhension du graphe. Des descriptions supplémentaires ont été intégrées pour enrichir les légendes, et la visualisation finale du réseau a été réalisée via visnetwork.\nIl est possible de voir via l’exemple suivant (obtenu avec le code de l’annexe : Script_R_reseau_co-auteur) qu’un réseau de co-auteurs permet une visualisation claire des collaborations et des périodes d’activité des différents auteurs.\n\n\n\nRéseau de co-auteurs\n\n\nA travers cet exemple, les limitations de la création de réseau sur les données récupérées via un identifiant de laboratoire transparaissent. De fait, on voit l’apparition de cercle de co-auteurs très denses. Ces cercles correspondent généralement à une unique publication contenant de nombreux auteurs.\n\n\n\nJ’ai tout de même réalisé un modèle en bloc stochastique sur ce réseau. (voir le code du script en annexe :Script_R_SBM). Pour cela j’ai créé une matrice d’adjacence vide et je l’ai remplie avec les connexions pondérées des nœuds, puis nettoyée pour la lisibilité et visualisée avec plotMyMatrix. Ensuite, un modèle SBM est estimé à partir de cette matrice, les nœuds sont classés en groupes colorés. Enfin, le réseau est visualisé avec visNetwork, incluant des options pour une meilleure compréhension et esthétique.\n\n\n\nApplication des couleurs d’appartenance des noeuds via le modèle\n\n\nL’apparition de groupes de noeuds avec des interactions similaires colorés était attendue. Or dans l’exemple suivant, des groupes d’une même couleur n’apparaissent pas et les noeuds avec des profils de connexion similaire ne semblent pas être placé dans un même groupe. C’est pourquoi, j’ai décidé sur conseil de mes tuteurs de réaliser les mêmes manipulations sur un sous-groupe de données ne contenant que celles des auteurs affiliés à une seule structure. Nous avons noté la présence d’un biais car certains auteurs n’étant plus affiliés à la structure ont toujours le tag de la structure dans leur compte HAL. Ils apparaissent affiliés à la structure sans l’être réellement. (voir le code du script en annexe :Script_R_Sous-groupe)\n\n\n\nApplication des couleurs d’appartenance des noeuds via le nouveau modèle sur le réseau de co-auteurs de l’UMR MIA - Paris Saclay\n\n\nDe plus, le sbm obtenu n’étant toujours pas satisfaisant, une autre proposition a été mise en avant, se contenter de réaliser un sbm sur les composantes connexes du réseau. Cela n’a pas été encore réalisé et fait partie des possibles améliorations future du package {managHAL}.\n\n\n\n\n\nAu cours de cette partie, plusieurs sujets seront abordés. Les limites actuelles du package {managHAL} et les possibles améliorations seront discutées. Les résultats obtenus seront replacés dans un contexte scientifique plus large. Enfin, les utilisations potentielles du package {managHAL} seront examinées.\nPremièrement, il est important de parler des limites rencontrées au cours de ce projet. Un des défis a été l’intégration de l’API HAL. Malgré mes efforts, l’API HAL s’est révélée complexe et souvent peu intuitive. En effet, il existe des centaines de champs pour récupérer des données sur l’API HAL. Cela m’a freiné dans la compréhension de l’API et dans la modification des fonctions utilisant cette dernière. Les erreurs rencontrées étaient souvent dues à une mauvaise récupération des données ou à une confusion de ma part par rapport au formatage de ces dernières. J’ai donc eu besoin de nombreuses heures de recherches, de débogage et de tests pour obtenir les résultats attendus.\nDe plus, bien que le code développé ait montré une certaine efficacité en terme de temps de calcul, il reste des marges d’amélioration. Par exemple, certaines parties du code pourraient être optimisées pour améliorer les performances des fonctions et réduire le temps de traitement. Remplacer les boucles for par apply, qui est optimisée et plus rapide, pourrait être une solution. De même, pour la création de réseaux et l’utilisation de modélisation en bloc stochastique, il est encore possible d’améliorer le temps de traitement en recherchant et modifiant les options des fonctions utilisées ou en créant des sous-groupes comme présenté dans les résultats.\nUne des ambitions de ce projet est de s’inscrire dans une dynamique de science ouverte. Le mémoire écrit et produit avec Quarto illustre cette démarche en rendant le mémoire et les résultats accessibles et reproductibles sur un répertoire GitHub (repositoryMémoire). S’il était possible de lier les résultats obtenus à des résultats provenant d’autres bases de données telles que WebOfScience, la valeur scientifique des recherches effectuées via le package {managHAL} pourrait être considérablement enrichie. Avant la fin du stage, je prévois de travailler sur la documentation et les tests. L’objectif est d’améliorer la documentation du code pour faciliter son utilisation par d’autres développeurs, de documenter les fonctions pour en faciliter l’utilisation par d’autres personnes, et d’ajouter des tests pour garantir la bonne fonctionnalité du package. Je prévois aussi d’ajouter de nouvelles fonctionnalités. Dans un premier temps, je souhaite coder les fonctions et sous-fonctions permettant de construire un réseau de co-auteurs plutôt que d’avoir un simple script R sur un document quarto. Puis, je souhaite coder les fonctions permettant d’obtenir un modèle en bloc stochastique via le package ‘sbm’. Cela permettrait de simplifier l’utilisation du package et de le rendre plus générique. Dans un second temps, je prévois de nettoyer le package entièrement et de vérifier qu’il est bien aux normes pour qu’il puisse être publié à la fin de mon stage.\nEn ce qui concerne les utilisations potentielles du package développé, en premier lieu, {managHAL} est destiné à être utilisé par les personnes voulant réaliser des rapports sur les dynamiques sous-jacentes des publications au sein d’un laboratoire. Ensuite, il est possible qu’il soit utilisé par les personnes souhaitant faire un rapport bibliographique ou réaliser des vérifications quant aux erreurs d’ajout de publications des chercheurs sur HAL. Enfin, il y a des parallèles intéressants à explorer avec d’autres domaines scientifiques, comme la biologie. Les méthodes utilisées pour l’analyse de réseaux sont génériques et utilisables sur d’autres types de réseaux, et les fonctions de visualisation de réseaux par exemple peuvent être utilisées pour d’autres utilisations telle la visualisation d’un réseau de régulation de gène.\nEn conclusion, ce stage a permis de réaliser des avancées significatives dans le développement de l’outil qu’est le package {managHAL} malgré les défis rencontrés. Les prochaines étapes incluront des optimisations et des développements supplémentaires pour renforcer l’impact et la portée du travail réalisé, tout en restant alignées avec les principes de la science ouverte. Cette démarche, combinée à une réflexion continue sur les objectifs et les résultats, permettra non seulement d’améliorer la qualité du travail actuel, mais aussi de poser les bases pour l’entretien du package par les futurs développeurs.\n\n\n\n\n\n\n\nload_team_table_url &lt;- function(filter_id = TRUE, date_cols,\n    url) {\n    idhal &lt;- NULL\n    tmp_file &lt;- paste0(tempfile(), \".xlsx\")\n    download.file(url = url, destfile = tmp_file, mode = \"wb\")\n    nbcol &lt;- ncol(readxl::read_xlsx(tmp_file, sheet = \"Membres\"))\n    col_types &lt;- rep(\"text\", nbcol)\n    col_types[date_cols] &lt;- \"date\"\n\n    table &lt;- readxl::read_xlsx(tmp_file, sheet = \"Membres\",\n        col_types = col_types) %&gt;%\n        dplyr::rename_with(clean_names) %&gt;%\n        dplyr::mutate_if(function(x) {\n            \"POSIXt\" %in% class(x)\n        }, ~format(.x, \"%d/%m/%Y\"))\n\n    if (filter_id) {\n        table &lt;- suppressWarnings(table %&gt;%\n            dplyr::filter(!is.na(as.numeric(idhal))) %&gt;%\n            dplyr::mutate(idhal = as.numeric(idhal)))\n    }\n\n    # Test if there is a column named 'id'\n    # Possibility to add mandatory columns in the\n    # future Just add 'OR'\n    if (!(\"idhal\" %in% names(table)) | !(\"nom\" %in%\n        names(table)) | !(\"prenom\" %in% names(table))) {\n        stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \")\n    }\n\n    return(table)\n}\n\nCette fonction permet le chargement d’un fichier csv depuis un url. Elle prend en entrée une adresse url, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\nload_team_table_csv &lt;- function(filter_id = TRUE,\n                                date_cols,\n                                filepath){\n  idhal &lt;- NULL\n  \n  # read the csv table  TODO : Add message error to guide user\n  # if sep is different than \";\" \n  # and if header = false\n  nbcol &lt;- ncol(read.csv(filepath, header = TRUE, sep = \";\", encoding = \"UTF-8\"))\n  \n  # define column types (dates or text if not dates)\n  col_types &lt;- rep(\"character\", nbcol)\n  col_types[date_cols] &lt;- 'character'\n  \n  table &lt;- read.csv(filepath,\n                    header = TRUE,\n                    sep = \";\",\n                    encoding = \"UTF-8\",\n                    colClasses = col_types\n  ) %&gt;% dplyr::rename_with(  # clean the columns names \n      clean_names\n    ) %&gt;%\n    dplyr::mutate_if(function(x) {  # Convert specified column to dates\n      \"POSIXt\" %in% class(x)\n    }, ~ format(.x, \"%d/%m/%Y\"))\n  \n  # Filter out rows without IDHAL\n  if (filter_id) {\n    idhal &lt;- table$idhal\n    table &lt;- table[which(!is.na(idhal)),]\n    table$idhal &lt;- as.numeric(idhal)\n    table$idhal[table$idhal == 0] &lt;- NA\n    table &lt;- table[which(!is.na(idhal)),]\n  }\n  \n  # Test if there is a column named \"id\"\n  # Possibility to add mandatory columns in the future\n  # Just add \"OR\"\n  if ( !(\"idhal\" %in% names(table)) | !(\"nom\" %in% names(table)) | !(\"prenom\" %in% names(table)) ) { stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \") }\n  \n  return(table)\n}\n\nCette fonction permet le chargement d’un fichier csv depuis une adresse locale de la machine de l’utilisateur. Elle prend en entrée une adresse locale d’un fichier csv, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\nload_team_table &lt;- function(filter_id = TRUE, date_cols = c(7,\n    8), filepath_or_url) {\n\n    # If the parameter is a URL\n    if (grepl(\"^https?://\", filepath_or_url)) {\n\n        # Call the load_team_table_url function\n        # with the URL\n        return(load_team_table_url(filter_id = filter_id,\n            date_cols = date_cols, url = filepath_or_url))\n    } else {\n\n        # Otherwise, it's a local file path; call\n        # the load_team_table_csv function with\n        # the local file path\n        return(load_team_table_csv(filter_id = filter_id,\n            date_cols = date_cols, filepath = filepath_or_url))\n    }\n}\n\nCette fonction permet le chargement d’un fichier csv depuis une adresse locale de la machine de l’utilisateur ou depuis une adresse url. Elle prend en entrée une adresse locale d’un fichier csv ou une URL, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\n#' load_team_table_csv\n#'\n#' This function loads a team table from a CSV file, allowing optional filtering \n#' based on the presence of an IDHAL an specifying which columns contain dates.\n#'\n#' @param filter_id erase person without IDHAL (default = TRUE)\n#' @param date_cols positions of dates columns, others will be read as text\n#' @param filepath the file path of the CSV table\n#'\n#' @export\n#'\n#' @importFrom magrittr %&gt;%\n#' @importFrom utils read.csv\n#'\n#' @return a data.frame containing information from team\n#'\n#' @examples\n#' \n#' \\dontrun{\n#' load_team_table_csv(filter_id = TRUE,\n#'                     date_cols = c(7,8),\n#'                     'C:/users/.../.../Classeur.csv')\n#' }\n\nCe script permet la création d’une documentation de fonction classique via la commande : devtools::document(). Elle est au format utilisé par {roxygen2}.\n\n\n\n\nHAL_query &lt;- function(id,\n                      date_min = NULL,\n                      date_max = NULL,\n                      format = c(\"csv\", \"bibtex\", \"json\", \"xml\", \"online\"),\n                      grouped = FALSE,\n                      type_id = c(\"person_id\", \"struct_id\"),\n                      maxrows = 1000,\n                      add_filters = list(),\n                      add_exclusions = list(\n                        status_i = 111,\n                        instance_s = c(\"sfo\", \"dumas\", \"memsic\", \"hceres\")\n                      ),\n                      add_outputs = character(0),\n                      sorted_by = c(\"producedDate_tdate\", \"desc\"),\n                      thesis_strict = T) {\n  \n  # ----- DEFAULT PARAM -------------------------------------------------------\n  online &lt;- format[[1]] == \"online\"\n  outputs &lt;- c(\n    \"docid\", \"halId_s\", \"version_i\", \"docType_s\", \"citationFull_s\",\n    \"citationRef_s\", \"publicationDate_tdate\", \"authFullNamePersonIDIDHal_fs\", add_outputs\n  )\n  filters &lt;- list(\n    docType_s = c(\"COMM\", \"ART\", \"OUV\", \"COUV\", \"DOUV\", \"POSTER\", \"SOFTWARE\", \"THESE\", \"HDR\")\n  )\n  filters[names(add_filters)] &lt;- add_filters\n  \n  exclusions &lt;- list()\n  exclusions[names(add_exclusions)] &lt;- add_exclusions\n  # ---------------------------------------------------------------------------\n  \n  # Url start\n  if (online) {\n    start_query &lt;- \"https://hal.archives-ouvertes.fr/search/index/?\"\n  } else {\n    start_query &lt;- paste0(\n      \"https://api.archives-ouvertes.fr/search/hal/\", # API HAL\n      \"?omitHeader=true\",                             # header ommited\n      \"&wt=\", format[[1]], \"&\"                        # csv, bibtex, ...\n    )\n  }\n  if (grouped) {\n    date_query &lt;- query_date_grouped_parsing(\n      id = id,\n      type_id = type_id,\n      date_min = date_min,\n      date_max = date_max,\n      online = online\n    )\n  } else {\n    date_query &lt;- query_date_ungrouped_parsing(\n      id = id,\n      type_id = type_id,\n      date_min = date_min,\n      date_max = date_max,\n      online = online\n    )\n  }\n  \n  filter_query &lt;- query_filter_parsing(\n    filters = filters, exclusions = exclusions,\n    online = online\n  )\n  if (thesis_strict & !online) {\n    add &lt;- \"&fq=NOT+(docType_s:(THESE+OR+HDR)+AND+submitType_s:(notice+OR+annex))\"\n  } else {\n    add &lt;- \"\"\n  }\n  \n  sorting_query &lt;- query_sort_parsing(sorted_by = sorted_by)\n  output_query &lt;- query_output_parsing(\n    outputs = outputs, n_row = maxrows,\n    online = online\n  )\n  obj &lt;- list(\n    urls = paste0(\n      start_query,\n      date_query,\n      filter_query,\n      add,\n      sorting_query,\n      output_query\n    ) %&gt;%\n      utils::URLencode(),\n    description = list(\n      idhal = id,\n      date_min = date_min,\n      date_max = date_max,\n      outputs = outputs,\n      format = format[[1]],\n      grouped = grouped,\n      maxrows = maxrows,\n      filters = filters,\n      exclusions = exclusions,\n      outputs = outputs,\n      sorted_by = sorted_by,\n      thesis_strict = thesis_strict\n    )\n  )\n  class(obj) &lt;- \"halUrl\"\n  return(obj)\n}\n\nCette fonction permet de créer une adresse url d’une requête à l’API HAL. Elle prend en entrée différents paramètres de spécification du rendu. Elle donne en sortie une URL.\n\n\n\n\n#### ------------------- Creation of a co-authors\n#### graph ------------------- ####\n\n#### --------- First part : Data extraction and\n#### cleaning\n\npublication_id_struc &lt;- publication_id_struc %&gt;%\n    mutate(Publication_Year = substr(publicationDate_tdate,\n        1, 4))\n\nfor (i in seq_along(publication_id_struc$structHasAlphaAuthIdHalPersonid_fs)) {\n    publication_id_struc$structHasAlphaAuthIdHalPersonid_fs[i] &lt;- gsub(\"\\\\\\\\\",\n        \"\", publication_id_struc$structHasAlphaAuthIdHalPersonid_fs[i])\n}\n\n# extraction of info on the authors\ndata_graph_authors &lt;- publication_id_struc %&gt;%\n    select(halId_s, Publication_Year, authFullNamePersonIDIDHal_fs) %&gt;%\n    separate_rows(authFullNamePersonIDIDHal_fs, sep = \",\") %&gt;%\n    separate(authFullNamePersonIDIDHal_fs, into = c(\"Full_Name\",\n        \"Person_ID\", \"idhal\"), sep = \"_FacetSep_\",\n        fill = \"right\") %&gt;%\n    mutate(across(c(Full_Name, Person_ID, idhal), as.character)) %&gt;%\n    mutate(Person_ID = ifelse(Person_ID == \"0\", NA,\n        Person_ID))\n\n# extraction of info on which authors belongs to\n# which structure at the times of the\n# publications\ndata_graph_author_struc &lt;- publication_id_struc %&gt;%\n    select(structHasAlphaAuthIdHalPersonid_fs) %&gt;%\n    separate_rows(structHasAlphaAuthIdHalPersonid_fs,\n        sep = \"_AlphaSep_\") %&gt;%\n    separate(structHasAlphaAuthIdHalPersonid_fs, into = c(\"id_name_struc\",\n        \"id_full_name\"), sep = \"_JoinSep_\") %&gt;%\n    separate(id_full_name, into = c(\"idhal_s\", \"Person_ID\",\n        \"Full_Name\"), sep = \"_FacetSep_\", fill = \"right\") %&gt;%\n    separate(id_name_struc, into = c(\"id_struc\", \"name_struc\"),\n        sep = \"_FacetSep_\", fill = \"right\") %&gt;%\n    separate(Full_Name, into = c(\"Full_Name\", \"First_Letter\"),\n        sep = \",\", fill = \"right\") %&gt;%\n    mutate(Person_ID = ifelse(Person_ID == \"0\", NA,\n        Person_ID))\n## data_graph_author_struc &lt;-\n## find_inconsistent_names_and_ids(data_graph_author_struc)\ndata_graph_authors &lt;- find_inconsistent_names_and_ids(data_graph_authors)\ndata_graph_authors &lt;- merge(data_graph_authors, data_graph_author_struc[,\n    c(\"Person_ID\", \"id_struc\")], by = \"Person_ID\",\n    all.x = TRUE)\n\n\n# Creation of false ids only for authors without\n# Person_ID addind a mark to know which one were\n# created and which were not\ndata_graph_authors$False_id_mark &lt;- !is.na(data_graph_authors$Person_ID)\nunique_authors_without_id_vec &lt;- unique(data_graph_authors$Full_Name[which(data_graph_authors$False_id_mark ==\n    FALSE)])  ##%&gt;%\n## distinct(Full_Name, .keep_all = TRUE) ##%&gt;%\n## filter(is.na(Person_ID))\n\n# to create my own ids\ncreation_id &lt;- function(unique_authors_no_id_name_column) {\n    ids &lt;- character(length(unique_authors_no_id_name_column))\n    count &lt;- 0\n    for (i in 1:length(unique_authors_no_id_name_column)) {\n        count &lt;- count + 1\n        ids[i] &lt;- count\n    }\n    return(ids)\n}\nunique_authors_without_id &lt;- data.frame(Full_Name = unique_authors_without_id_vec)\nunique_authors_without_id$False_Id = creation_id(unique_authors_without_id$Full_Name)\n\n# delete lines where False_Id equals Person_ID i\n# lose info here but one person out of a\n# thousands seems ok (to be tested)\nunique_authors_without_id &lt;- unique_authors_without_id %&gt;%\n    filter(!False_Id %in% data_graph_authors$Person_ID)\n\n\n# give a false id to all authors without person\n# id\ndata_graph_authors &lt;- data_graph_authors %&gt;%\n    left_join(unique_authors_without_id %&gt;%\n        select(Full_Name, False_Id), by = \"Full_Name\") %&gt;%\n    mutate(Person_ID = ifelse(is.na(Person_ID), False_Id,\n        Person_ID)) %&gt;%\n    select(-False_Id, -idhal)\n\n\n#### --------- Second part : Constructing and\n#### visualizing networks\n\n# Creating the 'edge list' and the 'node list' To\n# do so we first create the contingence matrix,\n# and then we applied the melt function\ncontingence_table = data_graph_authors %&gt;%\n    count(as.numeric(Person_ID), halId_s) %&gt;%\n    dplyr::select(-n) %&gt;%\n    table %&gt;%\n    as.matrix\ncontingence_matrix = contingence_table %*% t(contingence_table)\ncontingence_matrix[lower.tri(contingence_matrix)] = 1000  # We set 1000 in order to applied a filter later on (in order to avoid duplication with the melt function)\nmelt_matrix = melt(contingence_matrix)\ncolnames(melt_matrix) = c(\"from\", \"to\", \"value\")\nedge_list = melt_matrix %&gt;%\n    filter(from != to & !value %in% c(0, 1000)) %&gt;%\n    rename(width = value)\nnode_list = melt_matrix %&gt;%\n    filter(from == to) %&gt;%\n    dplyr::select(-to) %&gt;%\n    rename(id = from) %&gt;%\n    mutate(label = id)\n\n# Creating a group variable in the node_list in\n# order to set differents colors corresponding\n# with the different years\ndata_graph_authors$Publication_Year &lt;- as.numeric(as.character(data_graph_authors$Publication_Year))\ndf_group = data_graph_authors %&gt;%\n    summarise(group = as.character(floor(mean(Publication_Year))),\n        .by = Person_ID) %&gt;%\n    rename(id = Person_ID)\nnode_list$id &lt;- as.character(node_list$id)\nnode_list = node_list %&gt;%\n    left_join(df_group, by = \"id\")\n\n# Defining nodes and edges that will serve to\n# build a legend for edges and nodes sizes\n# (number of publications), and colors (years)\nrange_year = range(data_graph_authors$Publication_Year)\nnode_size = data.frame(id = c(\"A\", \"B\", \"C\"), value = c(1,\n    6, 15), label = c(\"A\", \"B\", \"C\"), group = \"Number of publications\")\nedge_size = data.frame(from = c(\"A\", \"B\", \"C\"), to = c(\"B\",\n    \"C\", \"A\"), width = c(1, 6, 15), label = c(\"1\",\n    \"6\", \"15\"))\nnode_colors = data.frame(id = as.character(range_year),\n    value = 1, label = as.character(range_year), group = as.character(range_year))\nedge_colors = data.frame(from = as.character(range_year),\n    to = as.character(range_year[c(2, 1)]), width = 1,\n    label = \"\")\nnode_list = rbind(node_list, node_size, node_colors)\nedge_list = rbind(edge_list %&gt;%\n    mutate(label = \"\"), edge_size, edge_colors)\nedge_list = edge_list %&gt;%\n    mutate(size = 20)\n\n# Defining colors for Publication year\ndf_col = data.frame(group = as.character(c(range_year[1]:range_year[2])),\n    color = colorRampPalette(colors = c(\"#35B779FF\",\n        \"#FDE725FF\"))(range_year[2] - range_year[1] +\n        1))\nnode_list = node_list %&gt;%\n    left_join(df_col, by = \"group\")\n\n# Legend nodes Defining colors for Publication\n# year\ndf_col_Legend = data.frame(label = as.character(c(range_year[1]:range_year[2])),\n    group = as.character(c(range_year[1]:range_year[2])),\n    color = colorRampPalette(colors = c(\"#35B779FF\",\n        \"#FDE725FF\"))(range_year[2] - range_year[1] +\n        1))\n\n# legend additional information table\nnode_info &lt;- data.frame(id = c(\"A\", \"B\", \"C\"), info = c(\"Additional info for node A\",\n    \"Additional info for node B\", \"Additional info for node C\"))\n\n# Join node_info with node_list to add the title\n# column to the legend nodes\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info, by = \"id\") %&gt;%\n    mutate(title = ifelse(!is.na(info), info, \"\")) %&gt;%\n    select(-info)  # remove the info column after using it to create the title\n\n# Convert idhal to character type\ncleaned_table &lt;- cleaned_table %&gt;%\n    mutate(idhal = as.character(idhal))\n\ntmp2 &lt;- data_graph_authors[data_graph_authors$Person_ID %in%\n    node_list$id, ]\nnode_info2 &lt;- tmp2 %&gt;%\n    select(Full_Name, Person_ID) %&gt;%\n    rename(id = Person_ID)\n\n# Constructing node_info3\ntmp3 &lt;- cleaned_table[cleaned_table$idhal %in% node_list$id,\n    ]\nnode_info3 &lt;- tmp3 %&gt;%\n    select(idhal, nom, prenom, unite, equipe) %&gt;%\n    rename(id = idhal)\n\n# Joining node_info2 with node_list to add the\n# title column\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info2, by = \"id\") %&gt;%\n    mutate(title_info = ifelse(!is.na(Full_Name), paste(\"Name:\",\n        Full_Name, \",\", \"numeric idHal:\", id), NA),\n        title = ifelse(title == \"\", title_info, title))\n\n# Joining node_info3 with node_list to add the\n# title column\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info3, by = \"id\") %&gt;%\n    mutate(title_info = ifelse(!is.na(nom), paste(\"Name:\",\n        paste(nom, prenom), \",\", \"Team:\", equipe, \",\",\n        \"Unit:\", unite, \",\", \"numeric idHal:\", id),\n        title_info)) %&gt;%\n    mutate(title = if_else(!is.na(nom), title_info,\n        title)) %&gt;%\n    select(-title_info)\n\nnode_list &lt;- node_list %&gt;%\n    distinct(node_list$id, .keep_all = TRUE)\n\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend(addNodes = df_col_Legend, main = \"Graph of co-authors\",\n        useGroups = FALSE) %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"equipe\") %&gt;%\n    visExport(type = \"jpeg\", name = \"Full_Network_Co-authors_Example_managHAL\",\n        label = \"Export as jpeg\")\n\nCe script permet la création d’un réseau de co-auteur à partir de données bibliographique HAL.\n\n\n\n\n# Création d'un réseau unipartite\nset.seed(42)  # Pour la reproductibilité \nunipartite &lt;- erdos.renyi.game(10, 0.3)\n# unipartite_graph &lt;- plot(unipartite, main =\n# 'Réseau Unipartite', width = 800, height = 600)\n# print(unipartite_graph)\nmatrice_adjacence_unipartite &lt;- as.matrix(unipartite,\n    \"adjacency\")\n\n# Création d'un réseau bipartite Noms des nœuds\nnodes_A &lt;- c(\"A1\", \"A2\", \"A3\")\nnodes_B &lt;- c(\"B1\", \"B2\", \"B3\", \"B4\")\n# Liste des arêtes\nedges &lt;- c(\"A1\", \"B1\", \"A1\", \"B2\", \"A2\", \"B1\", \"A2\",\n    \"B2\", \"A2\", \"B3\", \"A3\", \"B2\", \"A3\", \"B4\")\n# Création du graphe\nbipartite &lt;- graph(edges, directed = FALSE)\nV(bipartite)$type &lt;- bipartite_mapping(bipartite)$type\nplot(bipartite, layout = layout_as_bipartite, vertex.color = c(\"skyblue\",\n    \"salmon\")[V(bipartite)$type + 1], vertex.label.color = \"black\",\n    vertex.shape = \"circle\", vertex.size = 30, edge.width = 2,\n    main = \"Réseau Bipartite\")\nmatrice_adjacence_bipartite &lt;- as.matrix(bipartite,\n    \"adjacency\")\n\nCe script permet de créer les réseaux unipartites et bipartites présent dans les méthodes.\n\n\n\n\n# Create an empty adjacence matrix\nmatrice_adjacence &lt;- matrix(0, nrow = length(node_list$id),\n    ncol = length(node_list$id))\ncolnames(matrice_adjacence) &lt;- node_list$id\nrownames(matrice_adjacence) &lt;- node_list$id\n\n# fill in the adjacence matrix\nfor (k in 1:nrow(edge_list)) {\n    i &lt;- match(edge_list$from[k], node_list$id)\n    j &lt;- match(edge_list$to[k], node_list$id)\n    matrice_adjacence[i, j] &lt;- edge_list$width[k]\n}\n# deleting the legend lines\nmatrice_adjacence &lt;- matrice_adjacence[1:(nrow(matrice_adjacence) -\n    5), ]\nmatrice_adjacence &lt;- matrice_adjacence[, 1:(ncol(matrice_adjacence) -\n    5)]\n\nplotMyMatrix(matrice_adjacence, dimLabels = list(row = \"id\",\n    col = \"id\"))\n# Estimation of a simple SBM using the adjacence\n# matrix\nmy_model &lt;- estimateSimpleSBM(matrice_adjacence, model = \"poisson\",\n    dimLabels = c(\"id\"))\n# ne fonctionne pas sur quarto (l'acces au ancien\n# plot)\n\n# creation graph avec attribution des groupes\nload(\"C:/users/marti/OneDrive/Bureau/Stage/donnees_sbm.Rdata\")\ngroup_membership &lt;- apply(my_model$indMemberships,\n    1, which.max)\ngroup_colors &lt;- rainbow(max(group_membership))\ndf_col_group = data.frame(group = 1:17, group_colors)\nnode_list &lt;- node_list[1:(nrow(node_list) - 5), ]\ndf_col = data.frame(id &lt;- node_list$id, group_membership &lt;- group_membership,\n    color = df_col_group$group_colors[apply(my_model$indMemberships,\n        1, which.max)])\nnode_list$group = df_col$group_membership....apply.my_model.indMemberships..1..which.max.\nnode_list$color = df_col$color\n\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend() %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"color\")\n\nCe script permet de réaliser un modèle en bloc stochastiques depuis le réseau créé dans l’annexe Script_R_reseau_co-auteur.\n\n\n\n\n## test pour obtenir un sous groupe\nfind_info_author_associated_with_id_struc &lt;- function(data_frame_info_author_struc) {\n    data_info_author_associated_with_id_struc &lt;- data_frame_info_author_struc[data_frame_info_author_struc$id_struc ==\n        1002311, ]\n    return(data_info_author_associated_with_id_struc)\n}\ndata_test_info_author_id_struc &lt;- find_info_author_associated_with_id_struc(data_graph_author_struc)\ndata_graph_author_struc$Full_Name[data_graph_author_struc$id_struc ==\n    1002311]\ndata_test_info_author_id_struc &lt;- unique(data_test_info_author_id_struc)\n\n#### ------------------------------------------------------\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    separate(Full_Name, into = c(\"Nom\", \"Prenom\"),\n        extra = \"merge\", sep = \" \", fill = \"right\")\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    unite(\"Full_Name\", Prenom, Nom, sep = \" \")\ntemp_cleaned_data_author &lt;- NULL\ntemp_cleaned_data_author$Full_Name &lt;- managHAL:::clean_names(data_test_info_author_id_struc$Full_Name)\n# print inconsistent ids\ninconsistent_ids &lt;- find_inconsistent_ids(data_test_info_author_id_struc)\nif (length(inconsistent_ids$Person_ID &gt; 1)) {\n    message(paste0(\"Il y a \", length(inconsistent_ids$Person_ID),\n        \" auteurs ayant leurs identifiant(s) HAL mal associé(s) à leurs noms :\"))\n    print(inconsistent_ids$Person_ID)\n}\n# print inconsistent ids and names\ninconsistent_names_ids &lt;- find_inconsistent_names_ids(data_test_info_author_id_struc)\nif (length(inconsistent_names_ids$Full_Name &gt; 1)) {\n    message(paste0(\"Il y a \", length(inconsistent_names_ids$Full_Name),\n        \" Auteur ayant plusieurs formes auteurs ayant leurs identifiant(s) HAL mal associé(s) :\"))\n    print(inconsistent_names_ids$Full_Name)\n}\n# Replace Person_ID values in data_authors with\n# corresponding values from inconsistent_ids\ndata_test_info_author_id_struc$Person_ID &lt;- ifelse(data_test_info_author_id_struc$Full_Name %in%\n    inconsistent_ids$Full_Name, inconsistent_ids$Person_ID[match(data_test_info_author_id_struc$Full_Name,\n    inconsistent_ids$Full_Name)], data_test_info_author_id_struc$Person_ID)\ndata_test_info_author_id_struc &lt;- unique(data_test_info_author_id_struc)\n# Update the temporary data.frame\ntemp_cleaned_data_author$Person_ID &lt;- data_test_info_author_id_struc$Person_ID\n### 2nd version : via chatGPT\nfor (i in seq_len(nrow(inconsistent_names_ids))) {\n    idx &lt;- which(temp_cleaned_data_author$Full_Name ==\n        inconsistent_names_ids$Full_Name[i])\n\n    if (length(idx) == i) {\n        temp_cleaned_data_author$Person_ID[idx] &lt;- inconsistent_names_ids$Person_ID[i]\n    }\n}\n# My version : Replace Person_ID values in the\n# temporary dataframe for (i in\n# seq_len(nrow(inconsistent_names_ids))) {\n# temp_cleaned_data_author[temp_cleaned_data_author$Full_Name\n# == inconsistent_names_ids$Full_Name[i],\n# 'Person_ID'] &lt;-\n# inconsistent_names_ids$Person_ID[i] } Replace\n# Person_ID values in the original dataframe\ndata_test_info_author_id_struc$Person_ID &lt;- temp_cleaned_data_author$Person_ID\n\n#### -----------------------------------------------------------\n#### Create a logical vector for matching\n#### Full_Name\nmatch_vector &lt;- data_test_info_author_id_struc$Full_Name %in%\n    node_list$Full_Name\n# Print the match_vector to see which rows match\nprint(match_vector)\n# Assign Person_ID where Full_Name matches\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    mutate(Person_ID = ifelse(is.na(Person_ID) & Full_Name %in%\n        node_list$Full_Name, node_list$id[match(Full_Name,\n        node_list$Full_Name)], Person_ID))\n# Print the updated dataframe\nprint(data_test_info_author_id_struc)\nnode_list &lt;- node_list %&gt;%\n    filter(id %in% data_test_info_author_id_struc$Person_ID)\n# Filter edge_list to keep only rows where both\n# 'from' and 'to' are in\n# data_test_info_author_id_struc$Person_ID\nedge_list &lt;- edge_list %&gt;%\n    filter(from %in% data_test_info_author_id_struc$Person_ID &\n        to %in% data_test_info_author_id_struc$Person_ID)\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend(addNodes = df_col_Legend, main = \"Graph of Co-authors from MIA\",\n        useGroups = FALSE) %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"equipe\") %&gt;%\n    visExport(type = \"jpeg\", name = \"Full_Network_Co-authors_Example_managHAL\",\n        label = \"Export as jpeg\")\n## visSave(selfcontained = TRUE, file =\n## 'Partial_Network_Co-authors_Example_managHAL.html',\n## background = 'white' )\n## ------------------------------------------------------------------------\n## sbm Create an empty adjacence matrix\nmatrice_adjacence &lt;- matrix(0, nrow = length(node_list$id),\n    ncol = length(node_list$id))\ncolnames(matrice_adjacence) &lt;- node_list$id\nrownames(matrice_adjacence) &lt;- node_list$id\n# fill in the adjacence matrix\nfor (k in 1:nrow(edge_list)) {\n    i &lt;- match(edge_list$from[k], node_list$id)\n    j &lt;- match(edge_list$to[k], node_list$id)\n    matrice_adjacence[i, j] &lt;- edge_list$width[k]\n}\nplotMyMatrix(matrice_adjacence, dimLabels = list(row = \"id\",\n    col = \"id\"))\n# Estimation of a simple SBM using the adjacence\n# matrix\nmy_model &lt;- estimateSimpleSBM(matrice_adjacence, model = \"poisson\",\n    dimLabels = c(\"id\"))\n# ne fonctionne pas sur quarto (l'acces au ancien\n# plot)\nmy_model$nbBlocks\ngroup_membership &lt;- apply(my_model$indMemberships,\n    1, which.max)\ngroup_colors &lt;- rainbow(max(group_membership))\ndf_col_group = data.frame(group = 1:3, group_colors)\n## node_list &lt;- node_list[1:(nrow(node_list) -\n## 5), ] la legnende non presente car selection\n## labo\ndf_col = data.frame(id &lt;- node_list$id, group_membership &lt;- group_membership,\n    color = df_col_group$group_colors[apply(my_model$indMemberships,\n        1, which.max)])\nnode_list$group = df_col$group_membership....apply.my_model.indMemberships..1..which.max.\nnode_list$color = df_col$color\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend() %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"color\")\nplot(my_model, type = \"expected\")\n\nCe script permet de créer un sous-groupe du réseau, de construire un modèle en bloc stochastique à partir de ce nouveau réseau et de visualiser le tout.\n\n\n\n\n\n\n\n\n“About HAL.” n.d. https://about.hal.science/.\n\n\nAgroParisTech. 2024. “Science Ouverte.” https://www.agroparistech.fr/recherche/science-ouverte.\n\n\nAllaire, JJ, and Christophe Dervieux. 2024. “Quarto: R Interface to ’Quarto’ Markdown Publishing System.” https://CRAN.R-project.org/package=quarto.\n\n\nAubert, J., P. Barbillon, S. Donnet, and V. Miele. 2022. Using Latent Block Models to Detect Structure in Ecological Networks. Wiley. https://doi.org/10.1002/9781119902799.ch6.\n\n\nBache, Stefan Milton, and Hadley Wickham. 2022. “Magrittr: A Forward-Pipe Operator for r.” https://CRAN.R-project.org/package=magrittr.\n\n\nBengtsson, Henrik. 2021. “A Unifying Framework for Parallel and Distributed Processing in r Using Futures” 13. https://doi.org/10.32614/RJ-2021-048.\n\n\nBouchet-Valat, Milan. 2023. “SnowballC: Snowball Stemmers Based on the c ’Libstemmer’ UTF-8 Library.” https://CRAN.R-project.org/package=SnowballC.\n\n\nChiquet, Julien, Sophie Donnet, and Pierre Barbillon. 2020. “Sbm: Stochastic Blockmodels.” The R Foundation. https://doi.org/10.32614/cran.package.sbm.\n\n\n———. 2024. “Sbm: Stochastic Blockmodels.” https://CRAN.R-project.org/package=sbm.\n\n\n“Documentation API-HAL.” n.d. https://api.archives-ouvertes.fr/docs/search/?#q.\n\n\nFeinerer, Ingo, and Kurt Hornik. 2024. “Tm: Text Mining Package.” https://CRAN.R-project.org/package=tm.\n\n\nFellows, Ian. 2018. “Wordcloud: Word Clouds.” https://CRAN.R-project.org/package=wordcloud.\n\n\nIzrailev, Sergei. 2024. “Tictoc: Functions for Timing r Scripts, as Well as Implementations of \"Stack\" and \"StackList\" Structures.” https://CRAN.R-project.org/package=tictoc.\n\n\nMoral-Muñoz, José A., Enrique Herrera-Viedma, Antonio Santisteban-Espejo, and Manuel J. Cobo. 2020. “Software Tools for Conducting Bibliometric Analysis in Science: An up-to-Date Review.” El Profesional de La Información. https://doi.org/10.3145/epi.2020.ene.03.\n\n\nOoms, Jeroen. 2023. “Askpass: Password Entry Utilities for r, Git, and SSH.” https://CRAN.R-project.org/package=askpass.\n\n\nPremraj, Rahul. 2021. “mailR: A Utility to Send Emails from r.” https://CRAN.R-project.org/package=mailR.\n\n\nVaughan, Davis, and Matt Dancho. 2022. “Furrr: Apply Mapping Functions in Parallel Using Futures.” https://CRAN.R-project.org/package=furrr.\n\n\nWickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.” https://ggplot2.tidyverse.org.\n\n\n———. 2023. “Stringr: Simple, Consistent Wrappers for Common String Operations.” https://CRAN.R-project.org/package=stringr.\n\n\n———. 2024. “Rvest: Easily Harvest (Scrape) Web Pages.” https://CRAN.R-project.org/package=rvest.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. “Readxl: Read Excel Files.” https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. “Dplyr: A Grammar of Data Manipulation.” https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2023. “Purrr: Functional Programming Tools.” https://CRAN.R-project.org/package=purrr."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "En 2017, AgroParisTech signe l’Appel de Jussieu pour promouvoir la bibliodiversité, visant à maintenir la diversité éditoriale et éviter la domination des grands groupes éditeurs. AgroParisTech, en partenariat avec INRAE, adopte en 2020 une politique de science ouverte (AgroParisTech (2024), voir: La science ouverte à AgroParisTech – Politique d’établissement janvier 2020), facilitant la libre diffusion et la transparence des recherches scientifiques. Un exemple concret des principes appliqués suite à l’adoption de cette politique sont les principes FAIR pour la gestion des données de recherche : Findable (facilement trouvable), Accessible (accès clairement défini), Interoperable (intégrable avec d’autres outils), et Reusable (réutilisable avec toutes les informations nécessaires).\nPour atteindre ces objectifs, AgroParisTech crée le 2 janvier 2023 une cellule HAL, dirigée par la Direction de la Recherche, de l’Innovation et du Transfert Technologique, et par la Direction de la Documentation et du Patrimoine Culturel. Cette cellule facilite l’intégration de l’archive ouverte HAL dans la communauté de recherche d’AgroParisTech et veille à la qualité des métadonnées. HAL, ou HyperArticles en Lignes, est “l’archive nationale pour la diffusion ouverte des résultats de recherche” (“About HAL” (n.d.)). Elle est une plateforme en ligne développé en 2001 par le Centre pour la communication scientifique directe du CNRS. Cette plateforme dispose d’un API permettant l’extraction et l’analyse des données via des outils comme RStudio. Une explication plus détaillée de cet API et d’une requête HAL sera faite dans la section méthode.\n\n\n\nLes outils pour réaliser des analyses bibliométriques se répartissent en trois catégories, “general bibliometric and performance analysis, science mapping analysis, and libraries” (Moral-Muñoz et al. (2020)) ou analyse générale bibliométrique et de performances, analyses par cartographie scientifique et librairies / packages. Le package {managHAL} se trouve dans les troisième et deuxième catégories. Il existe à ce jour d’autres outils d’analyses bibliométriques mais la majorité ne permettent pas de travailler via l’api HAL et se concentrent sur webofscience, scopus, google scholar,… Il existe des outils d’extraction de publications HAL, cependant aucun package R ne permet actuellement d’extraire ces données pour réaliser des analyses statisistiques. Pour répondre à ce besoin, Théodore Vanrengterghem a commencé à développer le package R {managHAL}. Le package permet l’extraction de données HAL et la création de bilans bibliographiques. En cours de développement, ce package ne permet pas actuellement la réalisation d’analyses bibliométriques.\nAinsi, durant mes 2 mois et 17 jours de stage au sein de l’unité mixte de recherche Mathématiques et Informatique Appliquées (MIA) - Paris Saclay, associée aux tutelles AgroParisTech, INRAE et Université Paris Saclay, j’ai travaillé sur rendre le package {managHAL} plus accessible et utilisable par d’autres unités de recherches que l’unité MIA - Paris Saclay. J’ai aussi travaillé sur la programmation et l’intégration d’outils d’analyse statistique de réseau au sein du package. Encadré par deux tuteurs, Julie Aubert et Pierre Barbillon, j’ai contribué à la mise en forme du package et à la création de fonctions spécifiques.\nPour comprendre les choix réalisés lors du développement du package, il est nécessaire de réaliser une introduction aux réseaux. Un réseau d’interaction est constitué de nœuds (les entités) et d’arêtes (les liens entre ces entités). Dans le cadre du package {managHAl}, j’utiliserai les réseaux pour modéliser un réseau de co-publications (ou co-auteurs). Les noeuds représenteront des auteurs, et les arêtes entre ces noeuds (auteurs) seront l’existence de publications scientifiques co-écrite par les deux noeuds. La taille d’un nœud représentera le nombre de publications écrites par cet auteur (noeud) et la largeur d’une arête pourra correspondre au nombre de publications co-ecrites par les deux noeuds (co-auteurs). Les réseaux ne sont cependant pas exclusifs à l’analyse de données bibliométriques. En effet, les réseaux sont utilisés comme représentation et comme objet d’analyse statistique dans de nombreux domaines. Par exemple, des réseaux de régulations de gènes sont réalisés à partir de données de co-expression. Il est possible de donner d’autres exemples comme les analyses de réseaux d’interactions entre des espèces (réseau trophique) réalisées en écologie (analyse réalisée dans une vignette du package {sbm}). Les utilisations des réseaux sont nombreuses. L’introduction aux réseaux et leurs analyses sera approfondie dans la section méthodes.\nCe package s’adresse donc à un public souhaitant réaliser des analyses bibliométriques approfondies à partir de HAL. Nous verrons cependant dans la section discussion qu’il est possible d’élargir les usages du package."
  },
  {
    "objectID": "index.html#méthodes",
    "href": "index.html#méthodes",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "Cette partie est principalement basée sur la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022).\nLes réseaux se divisent en deux catégories principales (voir figures suivantes): les réseaux unipartites où tous les nœuds sont du même type et les réseaux bipartites où il y a deux types distincts de nœuds, et les liens ne se forment qu’entre des nœuds de types différents.(voir exemple_reseau_unipartite_bipartite pour le code de réalisation des réseaux d’exemple)\nExemple des deux types de réseaux\n \nLes interactions dans un réseau peuvent être binaires ou pondérées. Un réseau peut être représenté par une matrice d’adjacence \\(Y\\) où :\n\\[\\begin{align*}\nY_{ij} \\neq 0 & \\quad \\text{si un lien existe entre les nœuds } i \\text{ et } j, \\\\\nY_{ij} = 0 & \\quad \\text{si aucun lien n'existe entre les nœuds } i \\text{ et } j.\n\\end{align*}\\]\nNous décrivons les noeuds d’un réseau comme : \\(V = { 1,..,N }\\) , (\\(N\\) correspond à la taille du réseau). Les arêtes peuvent être décrites comme \\(E = \\{ (i,j) | i,j \\in V \\}\\) représentant les paires de nœuds entre lesquels il existe une interaction. Chaque arête \\((i,j)\\) indique une connexion entre les nœuds \\(i\\) et \\(j\\).\nIl existe plusieurs approches différentes pour analyser la structure d’un réseau. Dans ce mémoire, une seule approche sera considérée. Elle suppose l’existence de groupes fonctionnels partageant un même patron de connexion. Nous nous baserons par la suite sur une méthode possible pour cette approche: les modèles probabilistes génératifs.\nLes Modèles en Bloc Stochastiques (aussi appelés SBM) sont des modèles probabilistes. Ils supposent que les nœuds d’un même réseau sont divisés en blocs (groupes, clusters) latents regroupant les entités ayant des modèles de connectivité similaires. Latents signifie qu’il n’y a pas d’a priori sur le type de structure recherchée. Ces modèles sont utiles pour détecter les communautés, les clusters au sein d’un réseau complexe. Pour réaliser un modèle en bloc stochastique, il est nécessaire de supposer que le réseau obtenu à partir de mes données est une réalisation de mon modèle.\nLes noeuds sont partitionnés en \\(K\\) groupes latents. On définit un vecteur \\(Z\\) où \\(Zi = k\\) , \\(k\\) est le bloc auquel appartient le noeud \\(i\\) . Dans le cas d’un réseau unipartite, on définit :\n\n\\(P(Zi = k) = \\pi_k\\) , comme la probabilité d’appartenance au groupe \\(k\\).\n\\(P(Y_{ij} = 1 | Z_i = k, Z_j = k') = \\gamma_{kk'}\\) , comme la probabilité pour une paire de noeuds appartenant à un bloc \\(k\\) et à un bloc \\(k'\\) d’être en interaction (dans le cas binaire).\n\nNous avons donc comme paramètres du modèle \\(\\theta = (\\gamma, \\pi)\\). A partir du réseau connu, il est possible d’inférer les paramètres du modèle. Par nécessité d’écourter le rapport, une explication détaillée ne sera pas réalisée. Je vous conseille cependant d’aller voir la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022) où les explications à ce propos sont claires et précises.\n\n\n\nComme précisé dans l’introduction, l’intégralité des méthodes informatiques développées ont été réalisées sur RStudio en utilisant le langage R version 4.4.1 sous Windows 11 x64. Les packages utilisés sont les suivants :\nLe package {dplyr} (Wickham et al. 2023) est utilisé pour la manipulation et la transformation des données grâce à une syntaxe claire et cohérente. Ce package facilite les opérations courantes telles que la sélection, le filtrage, le regroupement et le résumé des données. Le package {mailR} (Premraj 2021) est utilisé pour l’envoi d’emails avec des pièces jointes directement depuis R, ce qui est utile pour automatiser l’envoi de rapports. Le package {askpass} (Ooms 2023) est utilisé pour gérer les mots de passe de manière sécurisée. Le package {furrr} (Vaughan and Dancho 2022) est utilisé pour paralléliser les tâches en combinaison avec le package future (Bengtsson 2021). Le package {future} (Bengtsson 2021) permet l’exécution de code en parallèle, ce qui réduit le temps de traitement des tâches lourdes. Le package {ggplot2} (Wickham 2016) est utilisé pour la création de visualisations graphiques sophistiquées. Le package {magrittr} (Bache and Wickham 2022) fournit des opérateurs pour améliorer la lisibilité du code, en particulier l’opérateur %&gt;% (pipe). Le package {purrr} (Wickham and Henry 2023) est utilisé pour les opérations fonctionnelles sur les listes et autres structures de données. Le package {quarto} (Allaire and Dervieux 2024) est utilisé pour la création de documents dynamiques et de rapports. Le package {readxl} (Wickham and Bryan 2023) permet la lecture de fichiers Excel. Le package {rvest} (Wickham 2024) est utilisé pour le web scraping, c’est-à-dire l’extraction de données à partir de pages web. Le package {SnowballC} (Bouchet-Valat 2023) est utilisé pour le traitement de la langue naturelle, en particulier pour la lemmatisation. Le package {stringr} (Wickham 2023) fournit des fonctions pour la manipulation des chaînes de caractères. Le package {tictoc} (Izrailev 2024) est utilisé pour mesurer le temps d’exécution des morceaux de code. Le package {tm} (Feinerer and Hornik 2024) est utilisé pour le text mining (extraction de connaissances à partir de textes). Le package {wordcloud} (Fellows 2018) est utilisé pour la création de nuages de mots. Le package {Visnetwork} (Chiquet, Donnet, and Barbillon 2020) est utilisé pour la visualisation de réseaux dynamiques. Le package {Sbm} (Chiquet, Donnet, and Barbillon 2024) est utilisé pour réaliser les analyses statistiques de réseaux.\nAfin de pouvoir construire une requête HAL pour récupérer des données bibliographiques de publications d’auteurs, il est nécessaire de comprendre comment construire une requête. Pour construire une requête HAL, il faut au moins un paramètre q qui contient la requête de recherche. Ce paramètre doit spécifier le champ de recherche suivi de la valeur. Par exemple, pour rechercher le terme “test” : http://api.archives-ouvertes.fr/search/?q=test&wt=xml . Si le champ n’est pas spécifié, la recherche s’effectue par défaut dans l’index texte. Pour rechercher dans un champ particulier, il faut utiliser champ:terme : http://api.archives-ouvertes.fr/search/?q=title_t:japon&wt=xml . Pour échapper certains caractères spéciaux utilisés par Apache Solr, utilisez \\. Par exemple, (1+1):2 devient \\(1\\+1\\)\\:2. (voir “Documentation API-HAL” (n.d.)). Il est possible d’indiquer le format de la réponse (sous-entendant le format des données récupérées) via le paramètre wt . Pour finir il est possible de spécifier les champs à retourner dans la réponse via le paramètre fl et de faire un filtre des données via le paramètre fq (“Documentation API-HAL” (n.d.)). Toutes les possibilités de l’API HAL n’ont pas été abordées dans ce court résumé. Il est pourtant compréhensible que l’API HAL est très diverse et permet une grande liberté à l’utilisateur pour l’extraction des données. De plus, il existe un nombre de champs considérables. Certains seront abordés par la suite dans la section résultats.\nPour finir, la totalité du stage s’est inscrit dans une dynamique de développement et d’intégration continue via la forge Gitlab d’INRAE. La forge GitLab, est un logiciel DevOps passant par le langage Git. Git est un système de contrôle, de versionning du code des développeurs gratuit et open source. Il permet à plusieurs développeurs de travailler sur un code sur un même dépôt et d’avancer ensemble par le biais de “merge”. “Merge” signifie que la personne modifiant un fichier contenant du code pousse en ligne sur le dépôt partagé , les modifications réalisées."
  },
  {
    "objectID": "index.html#résultats",
    "href": "index.html#résultats",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "Cette section présente les résultats obtenus au cours de mon stage. Elle est divisée en deux parties principales: Les modifications faites au package {managHAL} d’origine dans l’objectif de le rendre plus générique et plus accessible, puis l’ajout de fonctionnalités au package {managHAL}. Par choix, seulement certaines fonctions et scripts R du package sont abordés. L’exécution de ces derniers est réalisée par le biais d’un exemple. Cet exemple est basé sur des données de l’UMR MIA-Paris-Saclay. Chaque fonction est expliquée en détail, suivie des raisons justifiant son développement. Il est important de noter que mon stage se terminant le 26 juillet, Le package est encore en développement. Certaines fonctionnalités sont encore en travail. Les fonctions présentées fonctionnent dans le cadre de l’exemple. Si vous souhaitez exécuter les scripts fournis dans le mémoire, il est nécessaire d’avoir accès au package {managHAL}. Dans cette section, les noms de fonctions seront en italique et les noms des scripts R contenant les fonctions seront en gras.\n\n\nLors de mon stage, j’ai d’abord décidé de rendre le package plus accessible et générique. Pour ce faire, il m’était nécessaire de réorganiser et modifier certaines fonctions déjà présentes codées par Théodore Vanrengterghem.\n\n\nJ’ai commencé par modifier dans le fichier mia_table.R la fonction load_mia_table. A l’origine, cette fonction permettait le chargement d’un csv en ligne fourni par les Ressources Humaines depuis un serveur. Le fichier contient des informations telles que le nom, le prénom, l’idhal, l’équipe, etc, des personnes appartenant au labo. Cette fonction n’était pas générique. Ainsi, il était nécessaire de la modifier. J’ai fait le choix de renommer le fichier load_table.R. J’ai remplacé la fonction load_mia_table par trois fonctions load_team_table_csv, load_team_table_url, et load_team_table. J’ai aussi modifié la majorité des fonctions déjà présentes dans le package faisant appel à load_mia_table. Les paramètres en entrée des trois fonctions sont les même que la fonction load_mia_table d’origine avec l’ajout d’un paramètre permettant à l’utilisateur de rentrer l’adresse du fichier. J’ai ensuite créé une documentation via le package {roxygène2} conforme aux critères requis pour un package mis en ligne (veuillez vous référez à l’annexe : Exemple d’une documentation classique avec Roxygen2 ) pour chacune des trois fonctions.\nload_team_table_url permet de charger un csv dans RStudio depuis un fichier en ligne. J’ai décidé pour load_team_table_url de garder en majeur partie le code d’origine et de simplement le réadapter par soucis de temps. J’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table_url)\nload_team_table_csv est basée sur la construction de load_team_table_url. Je l’ai adapté pour pouvoir charger depuis un fichier local de la machine de l’utilisateur en utilisant read.csv. De même que dans load_team_table_url, j’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table_csv)\nEnfin, load_team_table appelle l’une des deux fonctions en fonction du type d’adresse fourni : URL ou chemin de fichier local. Le type de l’adresse est déterminé en utilisant grepl, qui utilise une expression régulière. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : load_team_table)\n\n\n\n\ndata_RH_csv_Example &lt;- load_team_table(filter_id = TRUE,\n    date_cols = c(6, 7), filepath_or_url = \"./data/Data_RH_Example.csv\")\n# afin de ne garder que les lignes avec un idhal\n# correct\ndata_RH_csv_Example &lt;- data_RH_csv_Example[which(!is.na(data_RH_csv_Example$idhal)),\n    ]\nhead(data_RH_csv_Example)\n\n  civilite       nom prenom statut  rattachement debut_contrat fin_contrat\n1       M. ADJAKOSSA   Éric    CEC AgroParisTech                          \n6      Mme    AUBERT  Julie     IR         INRAE                          \n8       M. BARBILLON Pierre     PR AgroParisTech                          \n  financement  equipe  unite               orcid  idhal\n1             SOLsTIS MIA PS 0000-0002-5280-0347 749339\n6             SOLsTIS MIA PS 0000-0001-5203-5748  15356\n8             SOLsTIS MIA PS 0000-0002-7766-7693  16750\n                       adresse_mail\n1   eric-houngla.adjakossa@inrae.fr\n6             julie.aubert@inrae.fr\n8 Pierre.Barbillon@Agroparistech.fr\n\n\nLors de l’application de la fonction load_team_table ci-dessus en utilisant le jeu de données test Data_RH_Example, on observe le chargement d’un csv contenant les colonnes d’origine du csv fournies en entrée. Les valeurs manquantes ou mal renseignées des idhals numériques ont été remplacées par des NAs. Les dates présentes dans les colonnes de dates spécifiées par l’utilisateur ont été nettoyées et ont le bon format.\n\n\n\nDans le package {managHAL} originel, il y avait deux fichiers contenant les fonctions nécessaires à la construction d’une requête HAL. Ces deux fichiers se nomment HAL_reports.R et HAL_queries.R. La fonction principale de construction d’une requête HAL est HAL_query. Elle prend en entrée différents paramètres et construit une url correspondant à une requête HAL. Ces différents paramètres définissent les différents champs, filtres, sorties demandées de la requête. Les champs de sortie ne convenant pas et manquait d’information pour la construction d’un réseau. Ainsi, après réflexion et discussion avec mes tuteurs Julie Aubert et Pierre Barbillon, j’ai modifié les différents champs de sorties afin d’obtenir les données nécessaires et essentielles à la construction d’un réseau. Par exemple, le champ ‘authFullNamePersonIDIDHal_fs’ permet de spécifier à HAL_query de récupérer les noms et les identifiants HAL numériques des autheurs d’une même publication. Le paramètre add_output ajouté par Théodore Vanrengterghem dans la fonction d’origine permet à l’utilisateur de rentrer des champs de sortie spécifiques en plus. Ce paramètre a été beaucoup utilisé au cours de ce stage dans la création de fonction permettant la création de réseau.\nLa fonction d’origine ne créer pas d’url d’une page permettant de récupérer les publications autres qu’à partir d’identifiants numériques d’auteurs, j’ai modifié les paramètres d’entrée et le corps de la fonction afin que l’utilisateur puissent spécifier si les identifiants fournis sont des identifiants de structures ou des identifiants de personnes. La nouvelle fonction HAL_query crée un url qui peut récupérer au choix de l’utilisateur une liste de publications associés à une structure via son identifiant ou une liste de publications associés à un identifiant numérique. (Pour voir le corps de la fonction, veuillez vous référer à l’annexe : HAL_query)\nPlusieurs fonctions présentes avant mes modifications faisait appel à HAL_query. Ces dernières comme HAL_extract_csv ont donc été modifiées afin de correspondre à la nouvelle version de HAL_query. De même Les fonctions auquelles fait appel HAL_query ont elles aussi été modifiées pour correspondre à HAL_query. HAL_extract_csv est une fonction récupèrant l’url via HAL_query. Pour montrer les résultats obtenus avec HAL_query, des exemples ci-dessous seront réalisés avec HAL_extract_csv pour une liste d’identifiants numérique d’auteurs et pour un identifiant d’une unité/laboratoire. Il sera ajouté des sorties via le paramètres add_outputs :\n\ndate_min = \"01/01/2022\"\ndate_max = \"01/01/2023\"\n\n# Publications à partir d'un id de laboratoire.\nHAL_publis_Labo &lt;- managHAL::HAL_extract_csv(id = 1002311,\n    date_min, date_max, type_id = \"struct_id\", add_output = c(\"structAcronym_s\",\n        \"structId_i\", \"structHasAlphaAuthIdHalPersonid_fs\"))\nHAL_publis_Labo[1, ]\n\n    docid      halId_s version_i docType_s\n1 4440523 hal-04440523         1      COMM\n                                                                                                                                                                                                                                                                                                                                                                         citationFull_s\n1 Isabelle Lebert, Maxime Rates, Julien Pradel, Laure Mathews-Martin, Aurore Latour, et al.. Evaluation du risque d’exposition aux tiques et aux agents de la maladie de Lyme dans les espaces verts de la région lyonnaise : résultats de la surveillance 2019-2023. Colloque final de restitution du projet Biodiversa-Bioroddi, Nov 2023, Lyon (Sciences Po), France. ⟨hal-04440523⟩\n                                                                                      citationRef_s\n1 Colloque final de restitution du projet Biodiversa-Bioroddi, Nov 2023, Lyon (Sciences Po), France\n  publicationDate_tdate\n1  2023-01-01T00:00:00Z\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    authFullNamePersonIDIDHal_fs\n1 Isabelle Lebert_FacetSep_184610_FacetSep_isabelle-lebert,Maxime Rates_FacetSep_749136_FacetSep_maxime-rates,Julien Pradel_FacetSep_1284695_FacetSep_,Laure Mathews-Martin_FacetSep_1310514_FacetSep_,Aurore Latour_FacetSep_0_FacetSep_,Maximilien Barbier_FacetSep_0_FacetSep_,Gwenaël Vourc’h_FacetSep_736823_FacetSep_gwenael-vourch,Valerie Poux_FacetSep_744163_FacetSep_valerie-poux,Séverine Barry_FacetSep_744034_FacetSep_severine-barry,Sébastien Masseglia_FacetSep_744051_FacetSep_sebastien-masseglia,Severine Bord_FacetSep_180861_FacetSep_severine-bord,Karine Chalvet-Monfray_FacetSep_743281_FacetSep_karine-chalvet-monfray,Diana Sepúlveda_FacetSep_0_FacetSep_,Luc Chabanne_FacetSep_754272_FacetSep_luc-chabanne,Nathalie Charbonnel_FacetSep_736426_FacetSep_nathalie-charbonnel,Magalie René-Martellet_FacetSep_744046_FacetSep_magalie-rene-martellet\n                                                                                               structAcronym_s\n1 UMR EPIA,VAS,INRAE,UMR CBGP,Cirad,IRD [France-Sud],INRAE,Institut Agro,UM,LRFSN,ANSES,MIA Paris-Saclay,INRAE\n                                                                                                                            structId_i\n1 1002382,301767,577435,1100832,11574,451860,577435,1096330,1042499,1100589,561191,301715,1002311,148117,419361,577435,1056557,1031275\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             structHasAlphaAuthIdHalPersonid_fs\n1 L_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,L_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,L_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_isabelle-lebert_FacetSep_184610_FacetSep_Lebert Isabelle,R_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,R_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,R_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_maxime-rates_FacetSep_749136_FacetSep_Rates Maxime,P_AlphaSep_1100832_FacetSep_Centre de Biologie pour la Gestion des Populations_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_11574_FacetSep_Centre de Coopération Internationale en Recherche Agronomique pour le Développement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_451860_FacetSep_Institut de Recherche pour le Développement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1096330_FacetSep_Institut Agro Montpellier_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1042499_FacetSep_Institut national d'enseignement supérieur pour l'agriculture\\\\, l'alimentation et l'environnement_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,P_AlphaSep_1100589_FacetSep_Université de Montpellier_JoinSep__FacetSep_1284695_FacetSep_Pradel Julien,M_AlphaSep_561191_FacetSep_Laboratoire de la rage et de la faune sauvage de Nancy_JoinSep__FacetSep_1310514_FacetSep_Mathews-Martin Laure,M_AlphaSep_301715_FacetSep_Agence nationale de sécurité sanitaire de l'alimentation\\\\, de l'environnement et du travail_JoinSep__FacetSep_1310514_FacetSep_Mathews-Martin Laure,L_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep__FacetSep_0_FacetSep_Latour Aurore,L_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep__FacetSep_0_FacetSep_Latour Aurore,L_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_0_FacetSep_Latour Aurore,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep__FacetSep_0_FacetSep_Barbier Maximilien,V_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,V_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,V_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_gwenael-vourch_FacetSep_736823_FacetSep_Vourc’h Gwenaël,P_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,P_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,P_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_valerie-poux_FacetSep_744163_FacetSep_Poux Valerie,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-barry_FacetSep_744034_FacetSep_Barry Séverine,M_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,M_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,M_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_sebastien-masseglia_FacetSep_744051_FacetSep_Masseglia Sébastien,B_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_1002311_FacetSep_Mathématiques et Informatique Appliquées_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_148117_FacetSep_AgroParisTech_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_419361_FacetSep_Université Paris-Saclay_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,B_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_severine-bord_FacetSep_180861_FacetSep_Bord Severine,C_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,C_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_karine-chalvet-monfray_FacetSep_743281_FacetSep_Chalvet-Monfray Karine,S_AlphaSep_1056557_FacetSep_Direction ‑ Écologie Urbaine de la Ville de Lyon_JoinSep__FacetSep_0_FacetSep_Sepúlveda Diana,S_AlphaSep_1031275_FacetSep_Partenaires INRAE_JoinSep__FacetSep_0_FacetSep_Sepúlveda Diana,C_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_luc-chabanne_FacetSep_754272_FacetSep_Chabanne Luc,C_AlphaSep_1100832_FacetSep_Centre de Biologie pour la Gestion des Populations_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_11574_FacetSep_Centre de Coopération Internationale en Recherche Agronomique pour le Développement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_451860_FacetSep_Institut de Recherche pour le Développement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1096330_FacetSep_Institut Agro Montpellier_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1042499_FacetSep_Institut national d'enseignement supérieur pour l'agriculture\\\\, l'alimentation et l'environnement_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,C_AlphaSep_1100589_FacetSep_Université de Montpellier_JoinSep_nathalie-charbonnel_FacetSep_736426_FacetSep_Charbonnel Nathalie,R_AlphaSep_1002382_FacetSep_Unité Mixte de Recherche d'Épidémiologie des maladies Animales et zoonotiques_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie,R_AlphaSep_301767_FacetSep_VetAgro Sup - Institut national d'enseignement supérieur et de recherche en alimentation\\\\, santé animale\\\\, sciences agronomiques et de l'environnement_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie,R_AlphaSep_577435_FacetSep_Institut National de Recherche pour l’Agriculture\\\\, l’Alimentation et l’Environnement_JoinSep_magalie-rene-martellet_FacetSep_744046_FacetSep_René-Martellet Magalie\n\n# Publications à partir d'ids auteurs\nHAL_publis_auteurs &lt;- managHAL::HAL_extract_csv(id = data_RH_csv_Example[,\n    12], date_min, date_max, type_id = \"person_id\")\nHAL_publis_auteurs[1, ]\n\n    docid      halId_s version_i docType_s\n1 4190551 hal-04190551         1       ART\n                                                                                                                                                                                                                                                                                citationFull_s\n1 Emmanuelle Blanc, Jérôme Enjalbert, Timothée Flutre, Pierre Barbillon. Efficient Bayesian automatic calibration of a functional-structural wheat model using an adaptive design and a metamodeling approach. Journal of Experimental Botany, In press, ⟨10.1093/jxb/erad339⟩. ⟨hal-04190551⟩\n                                                    citationRef_s\n1 Journal of Experimental Botany, In press, ⟨10.1093/jxb/erad339⟩\n  publicationDate_tdate\n1  2023-01-01T00:00:00Z\n                                                                                                                                                                                         authFullNamePersonIDIDHal_fs\n1 Emmanuelle Blanc_FacetSep_0_FacetSep_,Jérôme Enjalbert_FacetSep_1169771_FacetSep_jerome-enjalbert,Timothée Flutre_FacetSep_11756_FacetSep_timothee-flutre,Pierre Barbillon_FacetSep_16750_FacetSep_pierre-barbillon\n\n\n\n\n\n\n\n\nAfin d’obtenir les informations sous-jacentes des données bibliographiques, j’ai commencé à travailler à la création d’un réseau de co-auteur. Pour l’instant, la fonctionnalité n’existe qu’au format de script R sur un document quarto. Au cours des semaines restantes, l’objectif est de continuer à travailler dessus et créer des fonctions simples et claires permettant à l’utilisateur de créer son propre réseau à partir de ses données. Le script de création de fonction est inspiré d’un script fournie au préalable par ma tutrice Julie Aubert. Des modifications et des ajouts ont été apportés pour améliorer l’extraction, le nettoyage, la construction, et la visualisation des données. Suite à mes modifications et mes ajouts, le script se divise en plusieurs parties ((Pour voir le script R, veuillez vous référer à l’annexe : Script_R_reseau_co-auteur) :\nLa première partie correspond à l’extraction et au nettoyage des données. Les données brutes ont été organisées et nettoyées pour être adaptées à la construction du réseau. Les années de publication ont été extraites et les identifiants des auteurs ont été nettoyé. Les auteurs ont été associés aux structures pertinentes, et les incohérences de noms ou d’identifiants HAL ont été corrigées. Des identifiants fictifs ont été créés pour les auteurs sans identifiant.\nLa deuxième partie concerne la construction et la visualisation du graphe. À partir des données nettoyées, des matrices de contingence ont été créées. Ces matrices ont été converties en listes de nœuds (auteurs) et en listes d’arêtes (collaborations). Les nœuds ont été colorés et groupés en fonction des années de publication, et des légendes ont été ajoutées pour faciliter la compréhension du graphe. Des descriptions supplémentaires ont été intégrées pour enrichir les légendes, et la visualisation finale du réseau a été réalisée via visnetwork.\nIl est possible de voir via l’exemple suivant (obtenu avec le code de l’annexe : Script_R_reseau_co-auteur) qu’un réseau de co-auteurs permet une visualisation claire des collaborations et des périodes d’activité des différents auteurs.\n\n\n\nRéseau de co-auteurs\n\n\nA travers cet exemple, les limitations de la création de réseau sur les données récupérées via un identifiant de laboratoire transparaissent. De fait, on voit l’apparition de cercle de co-auteurs très denses. Ces cercles correspondent généralement à une unique publication contenant de nombreux auteurs.\n\n\n\nJ’ai tout de même réalisé un modèle en bloc stochastique sur ce réseau. (voir le code du script en annexe :Script_R_SBM). Pour cela j’ai créé une matrice d’adjacence vide et je l’ai remplie avec les connexions pondérées des nœuds, puis nettoyée pour la lisibilité et visualisée avec plotMyMatrix. Ensuite, un modèle SBM est estimé à partir de cette matrice, les nœuds sont classés en groupes colorés. Enfin, le réseau est visualisé avec visNetwork, incluant des options pour une meilleure compréhension et esthétique.\n\n\n\nApplication des couleurs d’appartenance des noeuds via le modèle\n\n\nL’apparition de groupes de noeuds avec des interactions similaires colorés était attendue. Or dans l’exemple suivant, des groupes d’une même couleur n’apparaissent pas et les noeuds avec des profils de connexion similaire ne semblent pas être placé dans un même groupe. C’est pourquoi, j’ai décidé sur conseil de mes tuteurs de réaliser les mêmes manipulations sur un sous-groupe de données ne contenant que celles des auteurs affiliés à une seule structure. Nous avons noté la présence d’un biais car certains auteurs n’étant plus affiliés à la structure ont toujours le tag de la structure dans leur compte HAL. Ils apparaissent affiliés à la structure sans l’être réellement. (voir le code du script en annexe :Script_R_Sous-groupe)\n\n\n\nApplication des couleurs d’appartenance des noeuds via le nouveau modèle sur le réseau de co-auteurs de l’UMR MIA - Paris Saclay\n\n\nDe plus, le sbm obtenu n’étant toujours pas satisfaisant, une autre proposition a été mise en avant, se contenter de réaliser un sbm sur les composantes connexes du réseau. Cela n’a pas été encore réalisé et fait partie des possibles améliorations future du package {managHAL}."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "Au cours de cette partie, plusieurs sujets seront abordés. Les limites actuelles du package {managHAL} et les possibles améliorations seront discutées. Les résultats obtenus seront replacés dans un contexte scientifique plus large. Enfin, les utilisations potentielles du package {managHAL} seront examinées.\nPremièrement, il est important de parler des limites rencontrées au cours de ce projet. Un des défis a été l’intégration de l’API HAL. Malgré mes efforts, l’API HAL s’est révélée complexe et souvent peu intuitive. En effet, il existe des centaines de champs pour récupérer des données sur l’API HAL. Cela m’a freiné dans la compréhension de l’API et dans la modification des fonctions utilisant cette dernière. Les erreurs rencontrées étaient souvent dues à une mauvaise récupération des données ou à une confusion de ma part par rapport au formatage de ces dernières. J’ai donc eu besoin de nombreuses heures de recherches, de débogage et de tests pour obtenir les résultats attendus.\nDe plus, bien que le code développé ait montré une certaine efficacité en terme de temps de calcul, il reste des marges d’amélioration. Par exemple, certaines parties du code pourraient être optimisées pour améliorer les performances des fonctions et réduire le temps de traitement. Remplacer les boucles for par apply, qui est optimisée et plus rapide, pourrait être une solution. De même, pour la création de réseaux et l’utilisation de modélisation en bloc stochastique, il est encore possible d’améliorer le temps de traitement en recherchant et modifiant les options des fonctions utilisées ou en créant des sous-groupes comme présenté dans les résultats.\nUne des ambitions de ce projet est de s’inscrire dans une dynamique de science ouverte. Le mémoire écrit et produit avec Quarto illustre cette démarche en rendant le mémoire et les résultats accessibles et reproductibles sur un répertoire GitHub (repositoryMémoire). S’il était possible de lier les résultats obtenus à des résultats provenant d’autres bases de données telles que WebOfScience, la valeur scientifique des recherches effectuées via le package {managHAL} pourrait être considérablement enrichie. Avant la fin du stage, je prévois de travailler sur la documentation et les tests. L’objectif est d’améliorer la documentation du code pour faciliter son utilisation par d’autres développeurs, de documenter les fonctions pour en faciliter l’utilisation par d’autres personnes, et d’ajouter des tests pour garantir la bonne fonctionnalité du package. Je prévois aussi d’ajouter de nouvelles fonctionnalités. Dans un premier temps, je souhaite coder les fonctions et sous-fonctions permettant de construire un réseau de co-auteurs plutôt que d’avoir un simple script R sur un document quarto. Puis, je souhaite coder les fonctions permettant d’obtenir un modèle en bloc stochastique via le package ‘sbm’. Cela permettrait de simplifier l’utilisation du package et de le rendre plus générique. Dans un second temps, je prévois de nettoyer le package entièrement et de vérifier qu’il est bien aux normes pour qu’il puisse être publié à la fin de mon stage.\nEn ce qui concerne les utilisations potentielles du package développé, en premier lieu, {managHAL} est destiné à être utilisé par les personnes voulant réaliser des rapports sur les dynamiques sous-jacentes des publications au sein d’un laboratoire. Ensuite, il est possible qu’il soit utilisé par les personnes souhaitant faire un rapport bibliographique ou réaliser des vérifications quant aux erreurs d’ajout de publications des chercheurs sur HAL. Enfin, il y a des parallèles intéressants à explorer avec d’autres domaines scientifiques, comme la biologie. Les méthodes utilisées pour l’analyse de réseaux sont génériques et utilisables sur d’autres types de réseaux, et les fonctions de visualisation de réseaux par exemple peuvent être utilisées pour d’autres utilisations telle la visualisation d’un réseau de régulation de gène.\nEn conclusion, ce stage a permis de réaliser des avancées significatives dans le développement de l’outil qu’est le package {managHAL} malgré les défis rencontrés. Les prochaines étapes incluront des optimisations et des développements supplémentaires pour renforcer l’impact et la portée du travail réalisé, tout en restant alignées avec les principes de la science ouverte. Cette démarche, combinée à une réflexion continue sur les objectifs et les résultats, permettra non seulement d’améliorer la qualité du travail actuel, mais aussi de poser les bases pour l’entretien du package par les futurs développeurs."
  },
  {
    "objectID": "index.html#annexes",
    "href": "index.html#annexes",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "load_team_table_url &lt;- function(filter_id = TRUE, date_cols,\n    url) {\n    idhal &lt;- NULL\n    tmp_file &lt;- paste0(tempfile(), \".xlsx\")\n    download.file(url = url, destfile = tmp_file, mode = \"wb\")\n    nbcol &lt;- ncol(readxl::read_xlsx(tmp_file, sheet = \"Membres\"))\n    col_types &lt;- rep(\"text\", nbcol)\n    col_types[date_cols] &lt;- \"date\"\n\n    table &lt;- readxl::read_xlsx(tmp_file, sheet = \"Membres\",\n        col_types = col_types) %&gt;%\n        dplyr::rename_with(clean_names) %&gt;%\n        dplyr::mutate_if(function(x) {\n            \"POSIXt\" %in% class(x)\n        }, ~format(.x, \"%d/%m/%Y\"))\n\n    if (filter_id) {\n        table &lt;- suppressWarnings(table %&gt;%\n            dplyr::filter(!is.na(as.numeric(idhal))) %&gt;%\n            dplyr::mutate(idhal = as.numeric(idhal)))\n    }\n\n    # Test if there is a column named 'id'\n    # Possibility to add mandatory columns in the\n    # future Just add 'OR'\n    if (!(\"idhal\" %in% names(table)) | !(\"nom\" %in%\n        names(table)) | !(\"prenom\" %in% names(table))) {\n        stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \")\n    }\n\n    return(table)\n}\n\nCette fonction permet le chargement d’un fichier csv depuis un url. Elle prend en entrée une adresse url, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\nload_team_table_csv &lt;- function(filter_id = TRUE,\n                                date_cols,\n                                filepath){\n  idhal &lt;- NULL\n  \n  # read the csv table  TODO : Add message error to guide user\n  # if sep is different than \";\" \n  # and if header = false\n  nbcol &lt;- ncol(read.csv(filepath, header = TRUE, sep = \";\", encoding = \"UTF-8\"))\n  \n  # define column types (dates or text if not dates)\n  col_types &lt;- rep(\"character\", nbcol)\n  col_types[date_cols] &lt;- 'character'\n  \n  table &lt;- read.csv(filepath,\n                    header = TRUE,\n                    sep = \";\",\n                    encoding = \"UTF-8\",\n                    colClasses = col_types\n  ) %&gt;% dplyr::rename_with(  # clean the columns names \n      clean_names\n    ) %&gt;%\n    dplyr::mutate_if(function(x) {  # Convert specified column to dates\n      \"POSIXt\" %in% class(x)\n    }, ~ format(.x, \"%d/%m/%Y\"))\n  \n  # Filter out rows without IDHAL\n  if (filter_id) {\n    idhal &lt;- table$idhal\n    table &lt;- table[which(!is.na(idhal)),]\n    table$idhal &lt;- as.numeric(idhal)\n    table$idhal[table$idhal == 0] &lt;- NA\n    table &lt;- table[which(!is.na(idhal)),]\n  }\n  \n  # Test if there is a column named \"id\"\n  # Possibility to add mandatory columns in the future\n  # Just add \"OR\"\n  if ( !(\"idhal\" %in% names(table)) | !(\"nom\" %in% names(table)) | !(\"prenom\" %in% names(table)) ) { stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \") }\n  \n  return(table)\n}\n\nCette fonction permet le chargement d’un fichier csv depuis une adresse locale de la machine de l’utilisateur. Elle prend en entrée une adresse locale d’un fichier csv, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\nload_team_table &lt;- function(filter_id = TRUE, date_cols = c(7,\n    8), filepath_or_url) {\n\n    # If the parameter is a URL\n    if (grepl(\"^https?://\", filepath_or_url)) {\n\n        # Call the load_team_table_url function\n        # with the URL\n        return(load_team_table_url(filter_id = filter_id,\n            date_cols = date_cols, url = filepath_or_url))\n    } else {\n\n        # Otherwise, it's a local file path; call\n        # the load_team_table_csv function with\n        # the local file path\n        return(load_team_table_csv(filter_id = filter_id,\n            date_cols = date_cols, filepath = filepath_or_url))\n    }\n}\n\nCette fonction permet le chargement d’un fichier csv depuis une adresse locale de la machine de l’utilisateur ou depuis une adresse url. Elle prend en entrée une adresse locale d’un fichier csv ou une URL, un booléen déterminant le nettoyage ou non des valeurs idHALs, et un vecteur contenant le numéro des colonnes de dates. Elle donne en sortie le chargement d’un fichier csv.\n\n\n\n\n#' load_team_table_csv\n#'\n#' This function loads a team table from a CSV file, allowing optional filtering \n#' based on the presence of an IDHAL an specifying which columns contain dates.\n#'\n#' @param filter_id erase person without IDHAL (default = TRUE)\n#' @param date_cols positions of dates columns, others will be read as text\n#' @param filepath the file path of the CSV table\n#'\n#' @export\n#'\n#' @importFrom magrittr %&gt;%\n#' @importFrom utils read.csv\n#'\n#' @return a data.frame containing information from team\n#'\n#' @examples\n#' \n#' \\dontrun{\n#' load_team_table_csv(filter_id = TRUE,\n#'                     date_cols = c(7,8),\n#'                     'C:/users/.../.../Classeur.csv')\n#' }\n\nCe script permet la création d’une documentation de fonction classique via la commande : devtools::document(). Elle est au format utilisé par {roxygen2}.\n\n\n\n\nHAL_query &lt;- function(id,\n                      date_min = NULL,\n                      date_max = NULL,\n                      format = c(\"csv\", \"bibtex\", \"json\", \"xml\", \"online\"),\n                      grouped = FALSE,\n                      type_id = c(\"person_id\", \"struct_id\"),\n                      maxrows = 1000,\n                      add_filters = list(),\n                      add_exclusions = list(\n                        status_i = 111,\n                        instance_s = c(\"sfo\", \"dumas\", \"memsic\", \"hceres\")\n                      ),\n                      add_outputs = character(0),\n                      sorted_by = c(\"producedDate_tdate\", \"desc\"),\n                      thesis_strict = T) {\n  \n  # ----- DEFAULT PARAM -------------------------------------------------------\n  online &lt;- format[[1]] == \"online\"\n  outputs &lt;- c(\n    \"docid\", \"halId_s\", \"version_i\", \"docType_s\", \"citationFull_s\",\n    \"citationRef_s\", \"publicationDate_tdate\", \"authFullNamePersonIDIDHal_fs\", add_outputs\n  )\n  filters &lt;- list(\n    docType_s = c(\"COMM\", \"ART\", \"OUV\", \"COUV\", \"DOUV\", \"POSTER\", \"SOFTWARE\", \"THESE\", \"HDR\")\n  )\n  filters[names(add_filters)] &lt;- add_filters\n  \n  exclusions &lt;- list()\n  exclusions[names(add_exclusions)] &lt;- add_exclusions\n  # ---------------------------------------------------------------------------\n  \n  # Url start\n  if (online) {\n    start_query &lt;- \"https://hal.archives-ouvertes.fr/search/index/?\"\n  } else {\n    start_query &lt;- paste0(\n      \"https://api.archives-ouvertes.fr/search/hal/\", # API HAL\n      \"?omitHeader=true\",                             # header ommited\n      \"&wt=\", format[[1]], \"&\"                        # csv, bibtex, ...\n    )\n  }\n  if (grouped) {\n    date_query &lt;- query_date_grouped_parsing(\n      id = id,\n      type_id = type_id,\n      date_min = date_min,\n      date_max = date_max,\n      online = online\n    )\n  } else {\n    date_query &lt;- query_date_ungrouped_parsing(\n      id = id,\n      type_id = type_id,\n      date_min = date_min,\n      date_max = date_max,\n      online = online\n    )\n  }\n  \n  filter_query &lt;- query_filter_parsing(\n    filters = filters, exclusions = exclusions,\n    online = online\n  )\n  if (thesis_strict & !online) {\n    add &lt;- \"&fq=NOT+(docType_s:(THESE+OR+HDR)+AND+submitType_s:(notice+OR+annex))\"\n  } else {\n    add &lt;- \"\"\n  }\n  \n  sorting_query &lt;- query_sort_parsing(sorted_by = sorted_by)\n  output_query &lt;- query_output_parsing(\n    outputs = outputs, n_row = maxrows,\n    online = online\n  )\n  obj &lt;- list(\n    urls = paste0(\n      start_query,\n      date_query,\n      filter_query,\n      add,\n      sorting_query,\n      output_query\n    ) %&gt;%\n      utils::URLencode(),\n    description = list(\n      idhal = id,\n      date_min = date_min,\n      date_max = date_max,\n      outputs = outputs,\n      format = format[[1]],\n      grouped = grouped,\n      maxrows = maxrows,\n      filters = filters,\n      exclusions = exclusions,\n      outputs = outputs,\n      sorted_by = sorted_by,\n      thesis_strict = thesis_strict\n    )\n  )\n  class(obj) &lt;- \"halUrl\"\n  return(obj)\n}\n\nCette fonction permet de créer une adresse url d’une requête à l’API HAL. Elle prend en entrée différents paramètres de spécification du rendu. Elle donne en sortie une URL.\n\n\n\n\n#### ------------------- Creation of a co-authors\n#### graph ------------------- ####\n\n#### --------- First part : Data extraction and\n#### cleaning\n\npublication_id_struc &lt;- publication_id_struc %&gt;%\n    mutate(Publication_Year = substr(publicationDate_tdate,\n        1, 4))\n\nfor (i in seq_along(publication_id_struc$structHasAlphaAuthIdHalPersonid_fs)) {\n    publication_id_struc$structHasAlphaAuthIdHalPersonid_fs[i] &lt;- gsub(\"\\\\\\\\\",\n        \"\", publication_id_struc$structHasAlphaAuthIdHalPersonid_fs[i])\n}\n\n# extraction of info on the authors\ndata_graph_authors &lt;- publication_id_struc %&gt;%\n    select(halId_s, Publication_Year, authFullNamePersonIDIDHal_fs) %&gt;%\n    separate_rows(authFullNamePersonIDIDHal_fs, sep = \",\") %&gt;%\n    separate(authFullNamePersonIDIDHal_fs, into = c(\"Full_Name\",\n        \"Person_ID\", \"idhal\"), sep = \"_FacetSep_\",\n        fill = \"right\") %&gt;%\n    mutate(across(c(Full_Name, Person_ID, idhal), as.character)) %&gt;%\n    mutate(Person_ID = ifelse(Person_ID == \"0\", NA,\n        Person_ID))\n\n# extraction of info on which authors belongs to\n# which structure at the times of the\n# publications\ndata_graph_author_struc &lt;- publication_id_struc %&gt;%\n    select(structHasAlphaAuthIdHalPersonid_fs) %&gt;%\n    separate_rows(structHasAlphaAuthIdHalPersonid_fs,\n        sep = \"_AlphaSep_\") %&gt;%\n    separate(structHasAlphaAuthIdHalPersonid_fs, into = c(\"id_name_struc\",\n        \"id_full_name\"), sep = \"_JoinSep_\") %&gt;%\n    separate(id_full_name, into = c(\"idhal_s\", \"Person_ID\",\n        \"Full_Name\"), sep = \"_FacetSep_\", fill = \"right\") %&gt;%\n    separate(id_name_struc, into = c(\"id_struc\", \"name_struc\"),\n        sep = \"_FacetSep_\", fill = \"right\") %&gt;%\n    separate(Full_Name, into = c(\"Full_Name\", \"First_Letter\"),\n        sep = \",\", fill = \"right\") %&gt;%\n    mutate(Person_ID = ifelse(Person_ID == \"0\", NA,\n        Person_ID))\n## data_graph_author_struc &lt;-\n## find_inconsistent_names_and_ids(data_graph_author_struc)\ndata_graph_authors &lt;- find_inconsistent_names_and_ids(data_graph_authors)\ndata_graph_authors &lt;- merge(data_graph_authors, data_graph_author_struc[,\n    c(\"Person_ID\", \"id_struc\")], by = \"Person_ID\",\n    all.x = TRUE)\n\n\n# Creation of false ids only for authors without\n# Person_ID addind a mark to know which one were\n# created and which were not\ndata_graph_authors$False_id_mark &lt;- !is.na(data_graph_authors$Person_ID)\nunique_authors_without_id_vec &lt;- unique(data_graph_authors$Full_Name[which(data_graph_authors$False_id_mark ==\n    FALSE)])  ##%&gt;%\n## distinct(Full_Name, .keep_all = TRUE) ##%&gt;%\n## filter(is.na(Person_ID))\n\n# to create my own ids\ncreation_id &lt;- function(unique_authors_no_id_name_column) {\n    ids &lt;- character(length(unique_authors_no_id_name_column))\n    count &lt;- 0\n    for (i in 1:length(unique_authors_no_id_name_column)) {\n        count &lt;- count + 1\n        ids[i] &lt;- count\n    }\n    return(ids)\n}\nunique_authors_without_id &lt;- data.frame(Full_Name = unique_authors_without_id_vec)\nunique_authors_without_id$False_Id = creation_id(unique_authors_without_id$Full_Name)\n\n# delete lines where False_Id equals Person_ID i\n# lose info here but one person out of a\n# thousands seems ok (to be tested)\nunique_authors_without_id &lt;- unique_authors_without_id %&gt;%\n    filter(!False_Id %in% data_graph_authors$Person_ID)\n\n\n# give a false id to all authors without person\n# id\ndata_graph_authors &lt;- data_graph_authors %&gt;%\n    left_join(unique_authors_without_id %&gt;%\n        select(Full_Name, False_Id), by = \"Full_Name\") %&gt;%\n    mutate(Person_ID = ifelse(is.na(Person_ID), False_Id,\n        Person_ID)) %&gt;%\n    select(-False_Id, -idhal)\n\n\n#### --------- Second part : Constructing and\n#### visualizing networks\n\n# Creating the 'edge list' and the 'node list' To\n# do so we first create the contingence matrix,\n# and then we applied the melt function\ncontingence_table = data_graph_authors %&gt;%\n    count(as.numeric(Person_ID), halId_s) %&gt;%\n    dplyr::select(-n) %&gt;%\n    table %&gt;%\n    as.matrix\ncontingence_matrix = contingence_table %*% t(contingence_table)\ncontingence_matrix[lower.tri(contingence_matrix)] = 1000  # We set 1000 in order to applied a filter later on (in order to avoid duplication with the melt function)\nmelt_matrix = melt(contingence_matrix)\ncolnames(melt_matrix) = c(\"from\", \"to\", \"value\")\nedge_list = melt_matrix %&gt;%\n    filter(from != to & !value %in% c(0, 1000)) %&gt;%\n    rename(width = value)\nnode_list = melt_matrix %&gt;%\n    filter(from == to) %&gt;%\n    dplyr::select(-to) %&gt;%\n    rename(id = from) %&gt;%\n    mutate(label = id)\n\n# Creating a group variable in the node_list in\n# order to set differents colors corresponding\n# with the different years\ndata_graph_authors$Publication_Year &lt;- as.numeric(as.character(data_graph_authors$Publication_Year))\ndf_group = data_graph_authors %&gt;%\n    summarise(group = as.character(floor(mean(Publication_Year))),\n        .by = Person_ID) %&gt;%\n    rename(id = Person_ID)\nnode_list$id &lt;- as.character(node_list$id)\nnode_list = node_list %&gt;%\n    left_join(df_group, by = \"id\")\n\n# Defining nodes and edges that will serve to\n# build a legend for edges and nodes sizes\n# (number of publications), and colors (years)\nrange_year = range(data_graph_authors$Publication_Year)\nnode_size = data.frame(id = c(\"A\", \"B\", \"C\"), value = c(1,\n    6, 15), label = c(\"A\", \"B\", \"C\"), group = \"Number of publications\")\nedge_size = data.frame(from = c(\"A\", \"B\", \"C\"), to = c(\"B\",\n    \"C\", \"A\"), width = c(1, 6, 15), label = c(\"1\",\n    \"6\", \"15\"))\nnode_colors = data.frame(id = as.character(range_year),\n    value = 1, label = as.character(range_year), group = as.character(range_year))\nedge_colors = data.frame(from = as.character(range_year),\n    to = as.character(range_year[c(2, 1)]), width = 1,\n    label = \"\")\nnode_list = rbind(node_list, node_size, node_colors)\nedge_list = rbind(edge_list %&gt;%\n    mutate(label = \"\"), edge_size, edge_colors)\nedge_list = edge_list %&gt;%\n    mutate(size = 20)\n\n# Defining colors for Publication year\ndf_col = data.frame(group = as.character(c(range_year[1]:range_year[2])),\n    color = colorRampPalette(colors = c(\"#35B779FF\",\n        \"#FDE725FF\"))(range_year[2] - range_year[1] +\n        1))\nnode_list = node_list %&gt;%\n    left_join(df_col, by = \"group\")\n\n# Legend nodes Defining colors for Publication\n# year\ndf_col_Legend = data.frame(label = as.character(c(range_year[1]:range_year[2])),\n    group = as.character(c(range_year[1]:range_year[2])),\n    color = colorRampPalette(colors = c(\"#35B779FF\",\n        \"#FDE725FF\"))(range_year[2] - range_year[1] +\n        1))\n\n# legend additional information table\nnode_info &lt;- data.frame(id = c(\"A\", \"B\", \"C\"), info = c(\"Additional info for node A\",\n    \"Additional info for node B\", \"Additional info for node C\"))\n\n# Join node_info with node_list to add the title\n# column to the legend nodes\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info, by = \"id\") %&gt;%\n    mutate(title = ifelse(!is.na(info), info, \"\")) %&gt;%\n    select(-info)  # remove the info column after using it to create the title\n\n# Convert idhal to character type\ncleaned_table &lt;- cleaned_table %&gt;%\n    mutate(idhal = as.character(idhal))\n\ntmp2 &lt;- data_graph_authors[data_graph_authors$Person_ID %in%\n    node_list$id, ]\nnode_info2 &lt;- tmp2 %&gt;%\n    select(Full_Name, Person_ID) %&gt;%\n    rename(id = Person_ID)\n\n# Constructing node_info3\ntmp3 &lt;- cleaned_table[cleaned_table$idhal %in% node_list$id,\n    ]\nnode_info3 &lt;- tmp3 %&gt;%\n    select(idhal, nom, prenom, unite, equipe) %&gt;%\n    rename(id = idhal)\n\n# Joining node_info2 with node_list to add the\n# title column\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info2, by = \"id\") %&gt;%\n    mutate(title_info = ifelse(!is.na(Full_Name), paste(\"Name:\",\n        Full_Name, \",\", \"numeric idHal:\", id), NA),\n        title = ifelse(title == \"\", title_info, title))\n\n# Joining node_info3 with node_list to add the\n# title column\nnode_list &lt;- node_list %&gt;%\n    left_join(node_info3, by = \"id\") %&gt;%\n    mutate(title_info = ifelse(!is.na(nom), paste(\"Name:\",\n        paste(nom, prenom), \",\", \"Team:\", equipe, \",\",\n        \"Unit:\", unite, \",\", \"numeric idHal:\", id),\n        title_info)) %&gt;%\n    mutate(title = if_else(!is.na(nom), title_info,\n        title)) %&gt;%\n    select(-title_info)\n\nnode_list &lt;- node_list %&gt;%\n    distinct(node_list$id, .keep_all = TRUE)\n\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend(addNodes = df_col_Legend, main = \"Graph of co-authors\",\n        useGroups = FALSE) %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"equipe\") %&gt;%\n    visExport(type = \"jpeg\", name = \"Full_Network_Co-authors_Example_managHAL\",\n        label = \"Export as jpeg\")\n\nCe script permet la création d’un réseau de co-auteur à partir de données bibliographique HAL.\n\n\n\n\n# Création d'un réseau unipartite\nset.seed(42)  # Pour la reproductibilité \nunipartite &lt;- erdos.renyi.game(10, 0.3)\n# unipartite_graph &lt;- plot(unipartite, main =\n# 'Réseau Unipartite', width = 800, height = 600)\n# print(unipartite_graph)\nmatrice_adjacence_unipartite &lt;- as.matrix(unipartite,\n    \"adjacency\")\n\n# Création d'un réseau bipartite Noms des nœuds\nnodes_A &lt;- c(\"A1\", \"A2\", \"A3\")\nnodes_B &lt;- c(\"B1\", \"B2\", \"B3\", \"B4\")\n# Liste des arêtes\nedges &lt;- c(\"A1\", \"B1\", \"A1\", \"B2\", \"A2\", \"B1\", \"A2\",\n    \"B2\", \"A2\", \"B3\", \"A3\", \"B2\", \"A3\", \"B4\")\n# Création du graphe\nbipartite &lt;- graph(edges, directed = FALSE)\nV(bipartite)$type &lt;- bipartite_mapping(bipartite)$type\nplot(bipartite, layout = layout_as_bipartite, vertex.color = c(\"skyblue\",\n    \"salmon\")[V(bipartite)$type + 1], vertex.label.color = \"black\",\n    vertex.shape = \"circle\", vertex.size = 30, edge.width = 2,\n    main = \"Réseau Bipartite\")\nmatrice_adjacence_bipartite &lt;- as.matrix(bipartite,\n    \"adjacency\")\n\nCe script permet de créer les réseaux unipartites et bipartites présent dans les méthodes.\n\n\n\n\n# Create an empty adjacence matrix\nmatrice_adjacence &lt;- matrix(0, nrow = length(node_list$id),\n    ncol = length(node_list$id))\ncolnames(matrice_adjacence) &lt;- node_list$id\nrownames(matrice_adjacence) &lt;- node_list$id\n\n# fill in the adjacence matrix\nfor (k in 1:nrow(edge_list)) {\n    i &lt;- match(edge_list$from[k], node_list$id)\n    j &lt;- match(edge_list$to[k], node_list$id)\n    matrice_adjacence[i, j] &lt;- edge_list$width[k]\n}\n# deleting the legend lines\nmatrice_adjacence &lt;- matrice_adjacence[1:(nrow(matrice_adjacence) -\n    5), ]\nmatrice_adjacence &lt;- matrice_adjacence[, 1:(ncol(matrice_adjacence) -\n    5)]\n\nplotMyMatrix(matrice_adjacence, dimLabels = list(row = \"id\",\n    col = \"id\"))\n# Estimation of a simple SBM using the adjacence\n# matrix\nmy_model &lt;- estimateSimpleSBM(matrice_adjacence, model = \"poisson\",\n    dimLabels = c(\"id\"))\n# ne fonctionne pas sur quarto (l'acces au ancien\n# plot)\n\n# creation graph avec attribution des groupes\nload(\"C:/users/marti/OneDrive/Bureau/Stage/donnees_sbm.Rdata\")\ngroup_membership &lt;- apply(my_model$indMemberships,\n    1, which.max)\ngroup_colors &lt;- rainbow(max(group_membership))\ndf_col_group = data.frame(group = 1:17, group_colors)\nnode_list &lt;- node_list[1:(nrow(node_list) - 5), ]\ndf_col = data.frame(id &lt;- node_list$id, group_membership &lt;- group_membership,\n    color = df_col_group$group_colors[apply(my_model$indMemberships,\n        1, which.max)])\nnode_list$group = df_col$group_membership....apply.my_model.indMemberships..1..which.max.\nnode_list$color = df_col$color\n\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend() %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"color\")\n\nCe script permet de réaliser un modèle en bloc stochastiques depuis le réseau créé dans l’annexe Script_R_reseau_co-auteur.\n\n\n\n\n## test pour obtenir un sous groupe\nfind_info_author_associated_with_id_struc &lt;- function(data_frame_info_author_struc) {\n    data_info_author_associated_with_id_struc &lt;- data_frame_info_author_struc[data_frame_info_author_struc$id_struc ==\n        1002311, ]\n    return(data_info_author_associated_with_id_struc)\n}\ndata_test_info_author_id_struc &lt;- find_info_author_associated_with_id_struc(data_graph_author_struc)\ndata_graph_author_struc$Full_Name[data_graph_author_struc$id_struc ==\n    1002311]\ndata_test_info_author_id_struc &lt;- unique(data_test_info_author_id_struc)\n\n#### ------------------------------------------------------\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    separate(Full_Name, into = c(\"Nom\", \"Prenom\"),\n        extra = \"merge\", sep = \" \", fill = \"right\")\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    unite(\"Full_Name\", Prenom, Nom, sep = \" \")\ntemp_cleaned_data_author &lt;- NULL\ntemp_cleaned_data_author$Full_Name &lt;- managHAL:::clean_names(data_test_info_author_id_struc$Full_Name)\n# print inconsistent ids\ninconsistent_ids &lt;- find_inconsistent_ids(data_test_info_author_id_struc)\nif (length(inconsistent_ids$Person_ID &gt; 1)) {\n    message(paste0(\"Il y a \", length(inconsistent_ids$Person_ID),\n        \" auteurs ayant leurs identifiant(s) HAL mal associé(s) à leurs noms :\"))\n    print(inconsistent_ids$Person_ID)\n}\n# print inconsistent ids and names\ninconsistent_names_ids &lt;- find_inconsistent_names_ids(data_test_info_author_id_struc)\nif (length(inconsistent_names_ids$Full_Name &gt; 1)) {\n    message(paste0(\"Il y a \", length(inconsistent_names_ids$Full_Name),\n        \" Auteur ayant plusieurs formes auteurs ayant leurs identifiant(s) HAL mal associé(s) :\"))\n    print(inconsistent_names_ids$Full_Name)\n}\n# Replace Person_ID values in data_authors with\n# corresponding values from inconsistent_ids\ndata_test_info_author_id_struc$Person_ID &lt;- ifelse(data_test_info_author_id_struc$Full_Name %in%\n    inconsistent_ids$Full_Name, inconsistent_ids$Person_ID[match(data_test_info_author_id_struc$Full_Name,\n    inconsistent_ids$Full_Name)], data_test_info_author_id_struc$Person_ID)\ndata_test_info_author_id_struc &lt;- unique(data_test_info_author_id_struc)\n# Update the temporary data.frame\ntemp_cleaned_data_author$Person_ID &lt;- data_test_info_author_id_struc$Person_ID\n### 2nd version : via chatGPT\nfor (i in seq_len(nrow(inconsistent_names_ids))) {\n    idx &lt;- which(temp_cleaned_data_author$Full_Name ==\n        inconsistent_names_ids$Full_Name[i])\n\n    if (length(idx) == i) {\n        temp_cleaned_data_author$Person_ID[idx] &lt;- inconsistent_names_ids$Person_ID[i]\n    }\n}\n# My version : Replace Person_ID values in the\n# temporary dataframe for (i in\n# seq_len(nrow(inconsistent_names_ids))) {\n# temp_cleaned_data_author[temp_cleaned_data_author$Full_Name\n# == inconsistent_names_ids$Full_Name[i],\n# 'Person_ID'] &lt;-\n# inconsistent_names_ids$Person_ID[i] } Replace\n# Person_ID values in the original dataframe\ndata_test_info_author_id_struc$Person_ID &lt;- temp_cleaned_data_author$Person_ID\n\n#### -----------------------------------------------------------\n#### Create a logical vector for matching\n#### Full_Name\nmatch_vector &lt;- data_test_info_author_id_struc$Full_Name %in%\n    node_list$Full_Name\n# Print the match_vector to see which rows match\nprint(match_vector)\n# Assign Person_ID where Full_Name matches\ndata_test_info_author_id_struc &lt;- data_test_info_author_id_struc %&gt;%\n    mutate(Person_ID = ifelse(is.na(Person_ID) & Full_Name %in%\n        node_list$Full_Name, node_list$id[match(Full_Name,\n        node_list$Full_Name)], Person_ID))\n# Print the updated dataframe\nprint(data_test_info_author_id_struc)\nnode_list &lt;- node_list %&gt;%\n    filter(id %in% data_test_info_author_id_struc$Person_ID)\n# Filter edge_list to keep only rows where both\n# 'from' and 'to' are in\n# data_test_info_author_id_struc$Person_ID\nedge_list &lt;- edge_list %&gt;%\n    filter(from %in% data_test_info_author_id_struc$Person_ID &\n        to %in% data_test_info_author_id_struc$Person_ID)\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend(addNodes = df_col_Legend, main = \"Graph of Co-authors from MIA\",\n        useGroups = FALSE) %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"equipe\") %&gt;%\n    visExport(type = \"jpeg\", name = \"Full_Network_Co-authors_Example_managHAL\",\n        label = \"Export as jpeg\")\n## visSave(selfcontained = TRUE, file =\n## 'Partial_Network_Co-authors_Example_managHAL.html',\n## background = 'white' )\n## ------------------------------------------------------------------------\n## sbm Create an empty adjacence matrix\nmatrice_adjacence &lt;- matrix(0, nrow = length(node_list$id),\n    ncol = length(node_list$id))\ncolnames(matrice_adjacence) &lt;- node_list$id\nrownames(matrice_adjacence) &lt;- node_list$id\n# fill in the adjacence matrix\nfor (k in 1:nrow(edge_list)) {\n    i &lt;- match(edge_list$from[k], node_list$id)\n    j &lt;- match(edge_list$to[k], node_list$id)\n    matrice_adjacence[i, j] &lt;- edge_list$width[k]\n}\nplotMyMatrix(matrice_adjacence, dimLabels = list(row = \"id\",\n    col = \"id\"))\n# Estimation of a simple SBM using the adjacence\n# matrix\nmy_model &lt;- estimateSimpleSBM(matrice_adjacence, model = \"poisson\",\n    dimLabels = c(\"id\"))\n# ne fonctionne pas sur quarto (l'acces au ancien\n# plot)\nmy_model$nbBlocks\ngroup_membership &lt;- apply(my_model$indMemberships,\n    1, which.max)\ngroup_colors &lt;- rainbow(max(group_membership))\ndf_col_group = data.frame(group = 1:3, group_colors)\n## node_list &lt;- node_list[1:(nrow(node_list) -\n## 5), ] la legnende non presente car selection\n## labo\ndf_col = data.frame(id &lt;- node_list$id, group_membership &lt;- group_membership,\n    color = df_col_group$group_colors[apply(my_model$indMemberships,\n        1, which.max)])\nnode_list$group = df_col$group_membership....apply.my_model.indMemberships..1..which.max.\nnode_list$color = df_col$color\n# Network visualization\nvisNetwork(node_list, edge_list, width = \"100%\") %&gt;%\n    visIgraphLayout() %&gt;%\n    visGroups(groupname = \"Number of publications\",\n        color = \"lightblue\", font = list(size = 22)) %&gt;%\n    visLegend() %&gt;%\n    visEdges(font = list(size = 22)) %&gt;%\n    visOptions(selectedBy = \"color\")\nplot(my_model, type = \"expected\")\n\nCe script permet de créer un sous-groupe du réseau, de construire un modèle en bloc stochastique à partir de ce nouveau réseau et de visualiser le tout."
  },
  {
    "objectID": "index.html#bibliographie",
    "href": "index.html#bibliographie",
    "title": "{MANAGHAL}, DONNEES BIBLIOMETRIQUES, RESEAUX ET ANALYSES STATISTIQUES DE RESEAUX",
    "section": "",
    "text": "“About HAL.” n.d. https://about.hal.science/.\n\n\nAgroParisTech. 2024. “Science Ouverte.” https://www.agroparistech.fr/recherche/science-ouverte.\n\n\nAllaire, JJ, and Christophe Dervieux. 2024. “Quarto: R Interface to ’Quarto’ Markdown Publishing System.” https://CRAN.R-project.org/package=quarto.\n\n\nAubert, J., P. Barbillon, S. Donnet, and V. Miele. 2022. Using Latent Block Models to Detect Structure in Ecological Networks. Wiley. https://doi.org/10.1002/9781119902799.ch6.\n\n\nBache, Stefan Milton, and Hadley Wickham. 2022. “Magrittr: A Forward-Pipe Operator for r.” https://CRAN.R-project.org/package=magrittr.\n\n\nBengtsson, Henrik. 2021. “A Unifying Framework for Parallel and Distributed Processing in r Using Futures” 13. https://doi.org/10.32614/RJ-2021-048.\n\n\nBouchet-Valat, Milan. 2023. “SnowballC: Snowball Stemmers Based on the c ’Libstemmer’ UTF-8 Library.” https://CRAN.R-project.org/package=SnowballC.\n\n\nChiquet, Julien, Sophie Donnet, and Pierre Barbillon. 2020. “Sbm: Stochastic Blockmodels.” The R Foundation. https://doi.org/10.32614/cran.package.sbm.\n\n\n———. 2024. “Sbm: Stochastic Blockmodels.” https://CRAN.R-project.org/package=sbm.\n\n\n“Documentation API-HAL.” n.d. https://api.archives-ouvertes.fr/docs/search/?#q.\n\n\nFeinerer, Ingo, and Kurt Hornik. 2024. “Tm: Text Mining Package.” https://CRAN.R-project.org/package=tm.\n\n\nFellows, Ian. 2018. “Wordcloud: Word Clouds.” https://CRAN.R-project.org/package=wordcloud.\n\n\nIzrailev, Sergei. 2024. “Tictoc: Functions for Timing r Scripts, as Well as Implementations of \"Stack\" and \"StackList\" Structures.” https://CRAN.R-project.org/package=tictoc.\n\n\nMoral-Muñoz, José A., Enrique Herrera-Viedma, Antonio Santisteban-Espejo, and Manuel J. Cobo. 2020. “Software Tools for Conducting Bibliometric Analysis in Science: An up-to-Date Review.” El Profesional de La Información. https://doi.org/10.3145/epi.2020.ene.03.\n\n\nOoms, Jeroen. 2023. “Askpass: Password Entry Utilities for r, Git, and SSH.” https://CRAN.R-project.org/package=askpass.\n\n\nPremraj, Rahul. 2021. “mailR: A Utility to Send Emails from r.” https://CRAN.R-project.org/package=mailR.\n\n\nVaughan, Davis, and Matt Dancho. 2022. “Furrr: Apply Mapping Functions in Parallel Using Futures.” https://CRAN.R-project.org/package=furrr.\n\n\nWickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.” https://ggplot2.tidyverse.org.\n\n\n———. 2023. “Stringr: Simple, Consistent Wrappers for Common String Operations.” https://CRAN.R-project.org/package=stringr.\n\n\n———. 2024. “Rvest: Easily Harvest (Scrape) Web Pages.” https://CRAN.R-project.org/package=rvest.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. “Readxl: Read Excel Files.” https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. “Dplyr: A Grammar of Data Manipulation.” https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2023. “Purrr: Functional Programming Tools.” https://CRAN.R-project.org/package=purrr."
  }
]