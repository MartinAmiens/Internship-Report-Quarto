[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ManagHAL",
    "section": "",
    "text": "0.1 INTRODUCTION\nEn 2017, AgroParisTech signe l’Appel de Jussieu. Cet appel a été rédigé dans l’objectif de mettre en avant des engagements pour promouvoir la Bibliodiversité. La bibliodiversité correspond à la diversité dans le monde éditorial afin d’éviter une appropriation des espaces de ventes par des grands groupes éditeurs. Dans la continuité de la signature de l’Appel de Jussieu, AgroParisTech en partenariat avec INRAE, a adopté en 2020, une politique d’établissement dédié à la science ouverte (AgroParisTech (2024) , voir : La science ouverte à AgroParisTech – Politique d’établissement janvier 2020). Pour AgroParisTech, la science ouverte correspond à l’ « ensemble des principes et des actions qui facilitent l’ouverture et la libre dissémination, à destination de l’ensemble de la société, des productions de la recherche scientifique, ainsi que la transparence et l’ouverture des processus de la recherche » (AgroParisTech (2024)) . Un exemple concret des principes appliqués par l’établissement sont les principes FAIR pour la gestion des données de recherches. Ces derniers stipulent que les données doivent être :\nAfin de progresser vers l’accomplissement des objectifs énoncés par AgroParisTech, de nombreuses actions ont été mises en place. Notamment, la création, le 2 janvier 2023, d’une cellule HAL au sein de l’établissement. Cette cellule HAL est dirigée par la Direction de la Recherche, de l’Innovation et du Transfert Technologique et par la Direction de la Documentation et du Patrimoine Culturelle. La cellule a pour vocation à faciliter l’intégration de l’archive ouverte HAL et des services associés dans la communauté de recherche d’AgroParisTech. Elle assure et veille à la qualité des métadonnées et référentiels pour le portail HAL-AgroParisTech (AgroParisTech (2024) , voir : Cellule HAL d’AgroParisTech Missions et Services). HAL est « l’archive nationale choisie par la communauté scientifique et universitaire française pour la diffusion ouverte de ses résultats de recherche. » (Comité d’orientation du CCSD & Assemblée des partenaires HAL (2022)). HAL dispose d’un API (Application Programming Interface) complexe et très diverse. Ce dernier est un programme permettant à d’autres applications comme Rstudio de communiquer et d’échanger des données avec HAL. L’API HAL offre de nombreux choix spécifiques dans l’extraction de données et dans l’analyse statistique de ces données. La construction d’une requète permettant la récupération de données HAL spécifiés par le constructeur de la requète passe par la connaissance de cet API. Une explication plus détaillée de cet API et d’une requète HAL sera faite dans la section méthode.\nBien qu’il existe des outils d’extraction de publications HAL et de création de rapport bibliographique en ligne comme ExtrHAL (LJonchere (n.d.)), il n’existe pas aujourd’hui de package R permettant d’extraire ces données et de réaliser des analyses statistiques sur ces dernières. C’est pourquoi en réponse à un besoin de l’unité MIA du partenariat entre AgroParisTech et INRAE, Théodore Vanrengterghem, ingénieur de recherche, s’est lancé dans la programmation d’un package R nommé “ManagHAL” réalisant l’extraction de donnée HAL et la création d’un bilan bibliographique.\nR est un langage de programmation gratuit et en open-source, qui a été conçu pour réaliser des analyses statistiques et manipuler des données. Rstudio, est l’environnement de programmation gratuit utilisant le langage R. Dans Rstudio, il existe la possibilité de télécharger des packages. Ces derniers sont des fichiers contenant des fonctions et des données qui partagent un même thème. Ils sont très utilisés par les utilisateurs de Rstudio car les packages facilitent le développement. Il existe actuellement plus de 18000 packages en ligne.\nDurant les 2 mois et 17 jours de mon stage, j’ai eu la chance d’être accueilli au sein du département Modélisation Mathématiques, Informatique, et Physique d’AgroParisTech Palaiseau dans l’unité de recherche Mathématiques et Informatiques Appliquées. Cette unité MIA est le résultat de la collaboration entre AgroParisTech et INRAE, J’ai eu l’opportunité d’être encadré par deux tuteurs nommés Julie Albert et Pierre Barbillon qui m’ont accompagné tout au long de cette expérience. L’unité Mathématiques et Informatiques Appliquées est composée de nombreux chercheurs, doctorants et stagiaire, et est hébergé au sein du bâtiment E d’AgroParisTech Palaiseau. J’ai travaillé sur l’adaptation, la programmation, et l’intégration d’outils de constructions de réseau, et d’outils d’analyse statistiques de réseau au package ManagHAL. J’ai donc pu travailler à la mise en forme du package, à la création de fonctions. Mon stage était financé par la Direction de la Recherche, de l’Innovation et du Transfert Technologique de la cellule HAL d’AgroParisTech présenté dans les paragraphes précédents.\nAfin de comprendre les choix que j’ai réalisé lors du développement du package, il est nécessaire de présenter le package d’origine avant mes modifications. Un point rapide sera fait au cours de la partie contexte statistique sur les réseaux et les méthodes d’analyse statistique de réseau que j’ai utilisé. Le package “ManagHAL” contenait des fichiers essentiels dans la construction d’un package R tel que buildRignore par exemple (contenant la liste des fichiers à ignorer lors de la construction du package sur l’ordinateur de l’utilisateur). Il contenait aussi des scripts R (i.e. files/fichiers) de fonctions contenant les fonctions principales du package. Celles-ci permettent de récupérer toutes les publications associées à un unique ou à des multiples identifiants d’auteurs HAL, provenant d’un fichier tabulé d’identifiants fournie par les ressources humaines. Lors de la récupération, il est possible de spécifier les données bilbiographiques des publications à récupérer. Ces dernières se présentent sous le format d’un fichier csv. Certaines de ces fonctions permettaient aussi de créer un rapport bibliographique automatique en ne donnant en entrée uniquement un identifiant auteur. Il existait des fonctions utiles au développement du package, afin de nettoyer mes données. Prenons par exemple “BorneDate” qui remplace les valeurs manquantes dans un vecteur de dates par une date limite spécifiée. Enfin, des fonctions permettaient réaliser des figures à partir des données des publications récupérés depuis HAL tel que des wordclouds ou des graphes.\nParagraphe précédent ne me convient pas, je vais le retravailler !!!\nLa finalité du package “ManagHAL” est de faciliter l’utilisation et la compréhension des données de publications. Afin de manipuler les données de publications et comprendre celles-ci, l’approche adoptée est de réaliser des réseaux et ensuite d’utiliser des outils d’analyse statistique de réseau. Les outils principaux utilisés à l’avenir dans “ManagHAL” seront les modélisations en blocs stochastiques ou latents. Mon mémoire est organisé de la manière suivante: En premier lieu, le contexte statistique nécessaire à la compréhension des outils utilisés est présenté. Puis, dans la partie suivante sont abordés, les méthodes informatiques développées et les résultats d’analyse de données-exemples obtenus. (pour lequel tout marche, précisez que je fais ça pcq mon stage n’est pas terminé). Dans un troisième temps, les méthodes déjà publiées utilisées sont précisées. Enfin, dans une ultime partie, les résultats sont discutés.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "ManagHAL",
    "section": "",
    "text": "Findable : facilement trouvable.\nAccessible : avec des conditions d’accès clairement définies.\nInteroperable : intégrable et capable d’interagir avec d’autres outils extérieurs ou données.\nReusable : réutilisables, avec toutes les informations nécessaires à la compréhension de ces dernières et au cadre d’utilisation autorisé par les auteurs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#contexte-statistique",
    "href": "index.html#contexte-statistique",
    "title": "ManagHAL",
    "section": "0.2 CONTEXTE STATISTIQUE",
    "text": "0.2 CONTEXTE STATISTIQUE\nCette partie est principalement basée sur la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022)\nUn réseau d’interaction est composé de nœuds (les entités) et d’arêtes (les liens entre ces entités). Toutes entités nommables peuvent être modèlisés sous forme de noeuds, et leur interactions entre elles peuent être modélisés par des arrêtes. On peut prendre pour exemple les réseaux de gènes à partir de données de co-expression. Les réseaux sont répartis en deux groupes principaux: les réseaux Unipartites, où tous les nœuds sont du même type, et les réseaux Bipartites, où il y a deux types distincts de nœuds et les liens ne se forme qu’entre des nœuds de types différents. Les interactions dans un réseau peuvent être binaires ou pondérées. Un réseau peut être encodé dans une matrice \\(Y\\) d’adjacence telle que :\n\\[\\begin{align*}\nY_{ij} \\neq 0 & \\quad \\text{si un lien existe entre les nœuds } i \\text{ et } j, \\\\\nY_{ij} = 0 & \\quad \\text{si aucun lien n'existe entre les nœuds } i \\text{ et } j.\n\\end{align*}\\]\nVous trouverez ci-dessous des exemples de code R pour créer et visualiser des réseaux unipartite et bipartite.\n\n# Création d'un réseau unipartite\nset.seed(42) # Pour la reproductibilité \nunipartite &lt;- erdos.renyi.game(10, 0.3)\n# unipartite_graph &lt;- plot(unipartite, main = \"Réseau Unipartite\", width = 800, height = 600)\n# print(unipartite_graph)\nmatrice_adjacence_unipartite &lt;- as.matrix(unipartite, \"adjacency\")\n\n# Création d'un réseau bipartite\n# Noms des nœuds\nnodes_A &lt;- c(\"A1\", \"A2\", \"A3\")\nnodes_B &lt;- c(\"B1\", \"B2\", \"B3\", \"B4\")\n# Liste des arêtes\nedges &lt;- c(\"A1\", \"B1\", \"A1\", \"B2\",\"A2\", \"B1\", \"A2\", \"B2\", \"A2\", \"B3\", \"A3\", \"B2\", \"A3\", \"B4\")\n# Création du graphe\nbipartite &lt;- graph(edges, directed = FALSE)\nV(bipartite)$type &lt;- bipartite_mapping(bipartite)$type\nplot(bipartite, layout = layout_as_bipartite, vertex.color = c(\"skyblue\", \"salmon\")[V(bipartite)$type + 1],\n     vertex.label.color = \"black\", vertex.shape = \"circle\", vertex.size = 30, edge.width = 2, main = \"Réseau Bipartite\")\nmatrice_adjacence_bipartite &lt;- as.matrix(bipartite, \"adjacency\")\n\n \nmettre une légende avec titre important !!!\nNous décrivons les noeuds d’un réseau comme : \\(V = { 1,..,N }\\) , (\\(N\\) correspond à la taille du réseau). Les arrêtes peuvent être décrit comme \\(E = ...\\) .\nIl existe plusieurs approches différentes pour analyser la structure d’un réseau. Dans ce mémoire, une seule approche sera considérée. Elle suppose l’existence de groupe fonctionnels partageant un même patron de connexion. Nous nous baserons par la suite sur une méthode possible pour cette approche: les modèles probabilistes génératifs.\nLes Modèles en Bloc Stochastiques (aussi appelé SBM) sont des modèles probabilistes. Ils supposent que les nœuds d’un même réseau sont divisés en blocs (groupe, clusters) latents regroupant les entités ayant des modèles de connectivité similaires. Latents signifie qu’il n’y a pas d’apriori sur le type de structure recherchée. Ces modèles sont utiles pour détecter les communautés, les clusters aux sein d’un réseau complexe. Pour réaliser un modèle en bloc stochastique, il est nécessaire de supposer que le réseau obtenu à partir de mes données est une réalisation de mon modèle.\nLes noeuds sont partitionnés en \\(K\\) groupes latents. On définit un vecteur \\(Z\\) où \\(Zi = k\\) , \\(k\\) est le bloc auquel appartient le noeud \\(i\\) . Dans le cas d’un réseau unipartite, on définit :\n\n\\(P(Zi = k) = \\pi_k\\) , comme la probabilité d’appartenance au groupe \\(k\\).\n\\(P(Y_{ij} = 1 | Z_i = k, Z_j = k') = \\gamma_{kk'}\\) , comme la probabilité pour une paire de noeuds appartenant à un bloc \\(k\\) et à un bloc \\(k'\\) d’être en interaction (dans le cas binaire).\n\nNous avons donc comme paramètres du modèle \\(\\theta = (\\gamma, \\pi)\\). A partir du réseau connu, il est possible d’inférer les paramètres du modèle. Par nécessité d’écourter le rapport, une explication détaillée ne sera pas réalisée. Je vous conseille cependant d’aller voir la publication “Using Latent Block Models to Detect Structure in Ecological Networks” Aubert et al. (2022) où les explications à ce propos sont claires et précises.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#methodes",
    "href": "index.html#methodes",
    "title": "ManagHAL",
    "section": "0.3 METHODES",
    "text": "0.3 METHODES\nComme précisé dans l’introduction, l’entièreté des méthodes informatiques développées ont été réalisées sur RStudio en utilisant le langage R version 4.4.1 sous windows 11 x64. Les packages utilisés sont les suivants :\nLe package “dplyr” est utilisé pour la manipulation et la transformation des données grâce à une syntaxe claire et cohérente. Ce package facilite les opérations courantes telles que la sélection, le filtrage, le regroupement et le résumé des données. Le package “mailR” est utilisé pour l’envoi d’emails avec des pièces jointes directement depuis R, ce qui est utile pour automatiser l’envoi de rapports. Le package “askpass” est utilisé pour gérer les mots de passe de manière sécurisée. Le package “furrr” est utilisé pour paralléliser les tâches en combinaison avec le package “future”. Le package “future” permet l’exécution de code en parallèle, ce qui réduit le temps de traitement des tâches lourdes. Le package “ggplot2” est utilisé pour la création de visualisations graphiques sophistiquées. Le package “magrittr” fournit des opérateurs pour améliorer la lisibilité du code, en particulier l’opérateur %&gt;% (pipe). Le package “purrr” est utilisé pour les opérations fonctionnelles sur les listes et autres structures de données. Le package “quarto” est utilisé pour la création de documents dynamiques et de rapports. Le package “readxl” permet la lecture de fichiers Excel. Le package “rvest” est utilisé pour le web scraping, c’est-à-dire l’extraction de données à partir de pages web. Le package “SnowballC” est utilisé pour le traitement de la langue naturelle, en particulier pour la lemmatisation. Le package “stringr” fournit des fonctions pour la manipulation des chaînes de caractères. Le package “tictoc” est utilisé pour mesurer le temps d’exécution des morceaux de code. Le package “tm” est utilisé pour le text mining (extraction de connaissances à partir de textes). Le package “wordcloud” est utilisé pour la création de nuages de mots.\nAfin de pouvoir construire une requète HAL pour récupèrer des données bibliographiques de publications d’auteurs, il est nécessaire de comprendre comment construire une requete.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#resultats",
    "href": "index.html#resultats",
    "title": "ManagHAL",
    "section": "0.4 RESULTATS",
    "text": "0.4 RESULTATS\nCette section présente les résultats obtenus au cours de mon stage. Elle est divisée en deux parties principales: les fonctions et algorithmes développés, modifiés ainsi que les résultats obtenus via un exemple. Cet exemple consistera en des données provenant des Ressources Humaines du Laboratoire MIA d’AgroPariTech. Chaque fonction est expliquée en détail, suivie des raisons justifiant son développement. Il est important de noter que mon stage se terminant le 26 juillet, Le package est donc encore en développement. Les fonctions présentées fonctionnent dans le cadre de l’exemple. Dans cette section, les noms de fonctions seront en italique et les noms des scripts R contenant les fonctions seront en gras.\n\n0.4.1 Accessibilité et généricité de ManagHAL\nLors de mon stage, j’ai d’abord décidé de rendre le package plus accessible et générique. Pour ce faire, il m’était nécessaire de réorganiser et modifier certaines fonctions déjà présentes codées par Théodore Vanrengterghem.\n\n0.4.1.1 Modifications de la fonction load_mia_table\nJ’ai commencé par modifier dans le fichier mia_table.R la fonction load_mia_table. A l’origine, cette fonction permettait le chargement d’un csv en ligne depuis une addresse spécifique vers un fichier contenant des informations tel que le nom, le prenom, l’idhal, l’equipe, etc, des personnes appartenant au labo. J’ai fait le choix de renommer le fichier load_table.R. J’ai remplacé la fonction load_mia_table par trois fonctions load_team_table_csv, load_team_table_url, et load_team_table. load_team_table_csv permet de charger un csv dans Rstudio depuis un fichier local de la machine de l’utilisateur. load_team_table_url permet de charger un csv dans Rstudio depuis un fichier en ligne. load_team_table fait appel aux deux fonctions précédentes et permet par le biais d’argument de fonctions de spécifier la provenance du fichier et de charger le csv soit depuis un url soit depuis un fichier local. J’ai aussi modifier la majorité des fonctions déjà présentes dans le package faisant appel à load_mia_table. Les paramètres en entrée des trois fonctions sont les même que la fonction load_mia_table d’origine avec l’ajout d’un paramètre permettant à l’utilisateur de rentrer l’adresse du fichier. J’ai ensuite crée une documentation via le package “Roxygène2” conforme aux critères requis pour un package mis en ligne (voir : exemple d’une documentation classique en annexe) pour chacune des trois fonctions.\nLa fonction originelle load_mia_table ne permettait que de charger de manière spécifique le csv fourni par les Ressources Humaines depuis un url seafile. Cette fonction n’était pas générique. Ainsi, il était nécéssaire de la modifier. J’ai décidé de diviser en trois fonctions différentes afin de permettre à l’utilisateur de choisir de charger des tables de provenance locale ou depuis internet. J’ai décidé pour load_team_table_url de garder en majeur partie le code d’origine et de simplement le réadapter par soucis de temps. J’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique.\n\nload_team_table_url &lt;- function(filter_id = TRUE,\n                                date_cols,\n                                url) {\n  idhal &lt;- NULL\n  tmp_file &lt;- paste0(tempfile(), \".xlsx\")\n  download.file(\n    url = url,\n    destfile = tmp_file,\n    mode = \"wb\"\n  )\n  nbcol &lt;- ncol(readxl::read_xlsx(tmp_file,\n                                  sheet = \"Membres\"))\n  col_types &lt;- rep(\"text\",nbcol)\n  col_types[date_cols] &lt;- 'date'\n  \n  \n  table &lt;- readxl::read_xlsx(tmp_file,\n                             sheet = \"Membres\",\n                             col_types = col_types\n  ) %&gt;%\n    dplyr::rename_with(\n      clean_names\n    ) %&gt;%\n    dplyr::mutate_if(function(x) {\n      \"POSIXt\" %in% class(x)\n    }, ~ format(.x, \"%d/%m/%Y\"))\n  \n  \n  if (filter_id) {\n    table &lt;- suppressWarnings(table %&gt;%\n                                dplyr::filter(!is.na(as.numeric(idhal))) %&gt;%\n                                dplyr::mutate(idhal = as.numeric(idhal)))\n  }\n  \n  # Test if there is a column named \"id\"\n  # Possibility to add mandatory columns in the future\n  # Just add \"OR\"\n  if ( !(\"idhal\" %in% names(table)) | !(\"nom\" %in% names(table)) | !(\"prenom\" %in% names(table)) ) { stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \") }\n  \n  return(table)\n}\n\nload_team_table_csv est basé sur la construction de load_team_table_url. Je l’ai adapté pour pouvoir charger depuis un fichier local en utilisant read.csv. De même que dans load_team_table_url, j’y ai ajouté des conditions de présence de colonnes obligatoires afin d’obliger l’utilisateur à fournir des colonnes sous un format spécifique.\n\nload_team_table_csv &lt;- function(filter_id = TRUE,\n                                date_cols,\n                                filepath){\n  idhal &lt;- NULL\n  nbcol &lt;- ncol(read.csv(filepath, header = TRUE, sep = \";\", encoding = \"UTF-8\"))\n  \n  # define column types (dates or text if not dates)\n  col_types &lt;- rep(\"character\", nbcol)\n  col_types[date_cols] &lt;- 'character'\n  \n  table &lt;- read.csv(filepath,\n                    header = TRUE,\n                    sep = \";\",\n                    encoding = \"UTF-8\",\n                    colClasses = col_types\n  ) %&gt;%\n    dplyr::rename_with(  # clean the columns names \n      clean_names\n    ) %&gt;%\n    dplyr::mutate_if(function(x) {  # Convert specified column to dates\n      \"POSIXt\" %in% class(x)\n    }, ~ format(.x, \"%d/%m/%Y\"))\n  \n  # Filter out rows without IDHAL\n  if (filter_id) {\n    idhal &lt;- table$idhal\n    table &lt;- table[which(!is.na(idhal)),]\n    table$idhal &lt;- as.numeric(idhal)\n    table$idhal[table$idhal == 0] &lt;- NA\n  }\n  \n  # Test if there is a column named \"id\"\n  # Possibility to add mandatory columns in the future\n  # Just add \"OR\"\n  if ( !(\"idhal\" %in% names(table)) | !(\"nom\" %in% names(table)) | !(\"prenom\" %in% names(table)) ) { stop(\"one of the following columns are missing : 'idhal' ; 'nom' ; 'prenom' \") }\n  \n  return(table)\n}\n\nEnfin, load_team_table appelle l’une des deux fonctions en fonction du type d’adresse fourni : URL ou chemin de fichier local. Le type de l’adresse est déterminé en utilisant grepl, qui utilise une expression régulière.\n\nload_team_table &lt;- function(filter_id = TRUE,\n                            date_cols = c(7,8),\n                            filepath_or_url) {\n  \n  # If the parameter is a URL\n  if (grepl(\"^https?://\", filepath_or_url)) {\n    \n    # Call the load_team_table_url function with the URL\n    return(load_team_table_url(filter_id = filter_id, date_cols = date_cols, url = filepath_or_url))\n  } else {\n    \n    # Otherwise, it's a local file path; call the load_team_table_csv function with the local file path\n    return(load_team_table_csv(filter_id = filter_id, date_cols = date_cols, filepath = filepath_or_url))\n  }\n}\n\n\n\n0.4.1.2 Résultat de l’Application de load_team_table\n\ndata_RH_csv_Example &lt;- load_team_table(filter_id = TRUE, date_cols = c(6,7), filepath_or_url = \"./data/Data_RH_Example.csv\")\nhead(data_RH_csv_Example)\n\n  civilite       nom   prenom   statut  rattachement debut_contrat fin_contrat\n1       M. ADJAKOSSA     Éric      CEC AgroParisTech                          \n2      Mme    ALBERT Isabelle       CR         INRAE                          \n3       M. ALLYNDREE   Joseph Doctorat AgroParisTech                          \n4      Mme   ALVAREZ Isabelle     IPEF         INRAE                          \n5       M.    ANAKOK     Emré Doctorat         INRAE    06/10/2021  05/10/2024\n6      Mme    AUBERT    Julie       IR         INRAE                          \n         financement  equipe  unite               orcid  idhal\n1                    SOLsTIS MIA PS 0000-0002-5280-0347 749339\n2                    SOLsTIS MIA PS 0000-0003-2686-917X     NA\n3                                                           NA\n4                    EkINocs MIA PS 0000-0002-5268-8666     NA\n5 ANR EcoNet/Mathnum SOLsTIS MIA PS 0000-0002-4439-4684     NA\n6                    SOLsTIS MIA PS 0000-0001-5203-5748  15356\n                     adresse_mail\n1 eric-houngla.adjakossa@inrae.fr\n2        Isabelle.Albert@inrae.fr\n3                                \n4       isabelle.alvarez@inrae.fr\n5            emre.anakok@inrae.fr\n6           julie.aubert@inrae.fr\n\n\nLors de l’application de la fonction load_team_table ci-dessus en utilisant le jeu de données test Data_RH_Example, on observe le chargement d’un csv contenant les colonnes d’origines du csv fournie en entrée. Les valeurs manquantes ou mal renseignées des idhals numériques ont été remplacées par des NAs. Les dates présentes deans les colonnes de dates spécifiés par l’utilisateur ont été nettoyées et ont le bon format.\n\n\n0.4.1.3 Modifications des fonctions régissant la requète HAL\nDans le package managHAL originel, il y avait deux fichiers contenant les fonctions nécéssaires à la construction d’une requète HAL. Ces deux fichiers se nomment HAL_reports.R et HAL_queries.R. La fonction principale de construction d’une requète HAL est HAL_query.\nParler des modification faites a HAL_query (add_outputs), pourquoi ? (je souhaite obtenir des informations bien particulières pour pouvoir coder le reseau de co-author et construire un sbm sur le reseau ?\n\n\n\n0.4.2 Conclusion des Résultats\nExemple via chatGPT\nLes méthodes développées au cours de ce stage ont permis d’améliorer significativement les performances des algorithmes existants. L’optimisation de l’algorithme X a réduit le temps de traitement de 40%, tandis que les ajustements apportés au modèle Y ont augmenté la précision de 5%. Ces résultats démontrent l’efficacité des approches choisies pour répondre aux limitations des méthodes précédentes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "ManagHAL",
    "section": "0.5 DISCUSSION",
    "text": "0.5 DISCUSSION\nparler de l’efficacité de ce que j’ai code, des modifications à venir et de ce que je souhaite faire avant la fin de stage. Parler de l’api HAL et du cauchemar que c’est, parler des potentiels utilisations du package pour HAL mais aussi faire un parallèle avec la bio avec par exemple en ouverture les réseaux de gènes ?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#annexes",
    "href": "index.html#annexes",
    "title": "ManagHAL",
    "section": "0.6 ANNEXES",
    "text": "0.6 ANNEXES\nExemple d’une documentation classique avec Roxygen2 :\n\n#' load_team_table_csv\n#'\n#' This function loads a team table from a CSV file, allowing optional filtering \n#' based on the presence of an IDHAL an specifying which columns contain dates.\n#'\n#' @param filter_id erase person without IDHAL (default = TRUE)\n#' @param date_cols positions of dates columns, others will be read as text\n#' @param filepath the file path of the CSV table\n#'\n#' @export\n#'\n#' @importFrom magrittr %&gt;%\n#' @importFrom utils read.csv\n#'\n#' @return a data.frame containing information from team\n#'\n#' @examples\n#' \n#' \\dontrun{\n#' load_team_table_csv(filter_id = TRUE,\n#'                     date_cols = c(7,8),\n#'                     \"C:/users/.../.../Classeur.csv\")\n#' }\n\n\n0.6.1 Tableau des résultats détaillés\nVoici les tableaux des résultats détaillés pour les différentes méthodes et tests effectués.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  },
  {
    "objectID": "index.html#bibliographie",
    "href": "index.html#bibliographie",
    "title": "ManagHAL",
    "section": "0.7 BIBLIOGRAPHIE",
    "text": "0.7 BIBLIOGRAPHIE\n\n\n\n\nAgroParisTech. 2024. “Science Ouverte.” https://www.agroparistech.fr/recherche/science-ouverte.\n\n\nAubert, J., P. Barbillon, S. Donnet, and V. Miele. 2022. Using Latent Block Models to Detect Structure in Ecological Networks. Wiley. https://doi.org/10.1002/9781119902799.ch6.\n\n\nComité d’orientation du CCSD & Assemblée des partenaires HAL, Comité de pilotage et. 2022. “HAL, Archive Ouverte Construite En Commun Pour Partager Et Diffuser La Connaissance Scientifique.” https://www.ccsd.cnrs.fr/wp-content/uploads/2023/01/DeclarationPolitiqueFR_VF.pdf.\n\n\nLJonchere, C. et al. n.d. “ExtrHAL - HALUR.” https://halur1.univ-rennes1.fr/ExtrHAL.php.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Mémoire de Stage</span>"
    ]
  }
]